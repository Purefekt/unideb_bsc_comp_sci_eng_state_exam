{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"INTRODUCTION PLEASE READ ALL THE SECTIONS BEFORE STARTING THE QUESTIONS TO CORRECT TYPOS, GRAMMATICAL ERRORS SEE CONTRIBUTING SECTION The state exam is a 20-minute speech that the student must give in front of 5-6 board members. The topic is randomly chosen using a random number generator and comes from a pool of 15 pre-defined topics posted HERE , under the heading 'Final exam topics'. You must log in using your Neptun ID to access this page. This link might change in the future, in which case please let me know by contributing on GitHub or sending me an email. These are the solutions to 'who started after 2017/2018/1'. The question will be selected using a random number generator and you will not be allowed to use any notes or a computer. You can create notes from memory in the 30 minute preparation time given to you. Each question has 2 subtopics, and you have to speak on both subtopics, roughly for 10 minutes each. These are my answers which I curated using multiple resources. My approach was to write around 2100 words per question or 1050 words per subtopic. These answers are written in a speech-like flow, with no diagrams, visuals, or formulas. IMPORTANT: Memorizing all 30k+ words in this document is stupid and will cause you to feel suicidal. These topics are core computer science engineering concepts, which means there's logic to everything. For each topic, watch simple explainer youtube videos with visuals so you can store that image in your head, and then while speaking, you can re-run it in your mind and that will make speaking easy. Use these answers as a guideline.","title":"Introduction"},{"location":"#introduction","text":"PLEASE READ ALL THE SECTIONS BEFORE STARTING THE QUESTIONS TO CORRECT TYPOS, GRAMMATICAL ERRORS SEE CONTRIBUTING SECTION The state exam is a 20-minute speech that the student must give in front of 5-6 board members. The topic is randomly chosen using a random number generator and comes from a pool of 15 pre-defined topics posted HERE , under the heading 'Final exam topics'. You must log in using your Neptun ID to access this page. This link might change in the future, in which case please let me know by contributing on GitHub or sending me an email. These are the solutions to 'who started after 2017/2018/1'. The question will be selected using a random number generator and you will not be allowed to use any notes or a computer. You can create notes from memory in the 30 minute preparation time given to you. Each question has 2 subtopics, and you have to speak on both subtopics, roughly for 10 minutes each. These are my answers which I curated using multiple resources. My approach was to write around 2100 words per question or 1050 words per subtopic. These answers are written in a speech-like flow, with no diagrams, visuals, or formulas. IMPORTANT: Memorizing all 30k+ words in this document is stupid and will cause you to feel suicidal. These topics are core computer science engineering concepts, which means there's logic to everything. For each topic, watch simple explainer youtube videos with visuals so you can store that image in your head, and then while speaking, you can re-run it in your mind and that will make speaking easy. Use these answers as a guideline.","title":"INTRODUCTION"},{"location":"2_about_the_author/","text":"ABOUT THE AUTHOR This website was developed by Veer Singh. I graduated from the University of Debrecen in December 2021 with a Bachelor of Science in Computer Science Engineering. You can find me here: DM me on Instagram @veer_singh99 Email me: veersingh230799@gmail.com Personal Website LinkedIn GitHub","title":"About the Author"},{"location":"2_about_the_author/#about-the-author","text":"This website was developed by Veer Singh. I graduated from the University of Debrecen in December 2021 with a Bachelor of Science in Computer Science Engineering. You can find me here: DM me on Instagram @veer_singh99 Email me: veersingh230799@gmail.com Personal Website LinkedIn GitHub","title":"ABOUT THE AUTHOR"},{"location":"3_importance_of_state_exam/","text":"IMPORTANCE OF THE STATE EXAM This 20-minute speech will count for 33% of your final degree GPA. The other 33% comes from the average of the grade your thesis supervisor gave you and the thesis defense grade (thesis defense happens right before the state exam). And the last 33% comes from the CGPA of all your courses taken in all the 3.5 years (7 semesters), except the thesis. So basically, doing well in these 20 minutes carries the same weightage as working hard for all the semesters, that is why you can boost your final GPA by acing the thesis and state exam.","title":"Importance of the State Exam"},{"location":"3_importance_of_state_exam/#importance-of-the-state-exam","text":"This 20-minute speech will count for 33% of your final degree GPA. The other 33% comes from the average of the grade your thesis supervisor gave you and the thesis defense grade (thesis defense happens right before the state exam). And the last 33% comes from the CGPA of all your courses taken in all the 3.5 years (7 semesters), except the thesis. So basically, doing well in these 20 minutes carries the same weightage as working hard for all the semesters, that is why you can boost your final GPA by acing the thesis and state exam.","title":"IMPORTANCE OF THE STATE EXAM"},{"location":"4_my_state_exam_experience/","text":"MY STATE EXAM EXPERIENCE My time slot was 8:00 am and my assigned number was 1, which meant I was the first on that day. There were 8 other Hungarian students of BSc. Computer Science Engineering and everyone was dressed in complete formals. When I entered the room, there were 5 board members and one assistant sitting on the left. The president of the board was mediating the whole thing. He told me to copy my thesis ppt to the projector laptop and start. I had my thesis ppt on a USB drive, so I copied it, they gave me a pointer with which I could move the slides. I started speaking, but keep in mind to go fast, since I was taking too long because I had a lot of material, the president of the board nudged me to speed up. Once I was done presenting, the president of the board asked the others if they had any questions, everyone said no. Then he asked me a simple question about the dataset I used in my thesis. Once the thesis presentation was done, the president of the board ran a random number generator and I got the number 10. He gave me a copy of the topics of the state exam containing all 15 questions, empty pieces of paper and told me I had 30 minutes to prepare topic number 10. Luckily topic 10 was one of my best-prepared topics so I asked them if I can start right away. I sat down in the chair and started speaking the first subtopic. I spoke fast, almost rapping, and in great detail. Halfway into answering the first subtopic, the president of the board told me to stop and asked if anyone had any questions, everyone said no. Then I started talking about the 2nd subtopic, again speaking fast and in great detail. Again the president told me to stop, he asked if anyone had any questions, everyone said no. This time he asked me a tricky question about the 2nd subtopic, and I answered it best to my knowledge. Once I was done, I left the room and they told me that I will get the results around 1:00 pm. At this point, the next person goes in, and slowly everyone on that day gets their thesis defense and state exam done. On my day there were 9 of us, and around 12:30 pm, everyone was done. Then they told us to wait another 30 minutes. Then they called all of us inside, all the board members were now standing and the 9 of us were standing on the opposite side. The president of the board asked for our consent to say the grades out loud and he started telling the grades of the thesis defense and the state exam in the original order. Since I was the first, he said 5 in thesis defense and 5 in state exam and then moved on to the others. Once everyone's grades were told, everyone shook hands and left. A few hours after that, I got a message on Neptun that my student status has been changed to 'Graduated' and my final grade was available on Neptun -> Studies -> Training Data under the Diploma section. 10 days after this, I got my original Degree Certificate and Diploma Supplement. The degree certificate is a single-page document saying you graduated from this university in this course. The diploma supplement includes more detailed information including the transcript of all courses taken.","title":"My State Exam Experience"},{"location":"4_my_state_exam_experience/#my-state-exam-experience","text":"My time slot was 8:00 am and my assigned number was 1, which meant I was the first on that day. There were 8 other Hungarian students of BSc. Computer Science Engineering and everyone was dressed in complete formals. When I entered the room, there were 5 board members and one assistant sitting on the left. The president of the board was mediating the whole thing. He told me to copy my thesis ppt to the projector laptop and start. I had my thesis ppt on a USB drive, so I copied it, they gave me a pointer with which I could move the slides. I started speaking, but keep in mind to go fast, since I was taking too long because I had a lot of material, the president of the board nudged me to speed up. Once I was done presenting, the president of the board asked the others if they had any questions, everyone said no. Then he asked me a simple question about the dataset I used in my thesis. Once the thesis presentation was done, the president of the board ran a random number generator and I got the number 10. He gave me a copy of the topics of the state exam containing all 15 questions, empty pieces of paper and told me I had 30 minutes to prepare topic number 10. Luckily topic 10 was one of my best-prepared topics so I asked them if I can start right away. I sat down in the chair and started speaking the first subtopic. I spoke fast, almost rapping, and in great detail. Halfway into answering the first subtopic, the president of the board told me to stop and asked if anyone had any questions, everyone said no. Then I started talking about the 2nd subtopic, again speaking fast and in great detail. Again the president told me to stop, he asked if anyone had any questions, everyone said no. This time he asked me a tricky question about the 2nd subtopic, and I answered it best to my knowledge. Once I was done, I left the room and they told me that I will get the results around 1:00 pm. At this point, the next person goes in, and slowly everyone on that day gets their thesis defense and state exam done. On my day there were 9 of us, and around 12:30 pm, everyone was done. Then they told us to wait another 30 minutes. Then they called all of us inside, all the board members were now standing and the 9 of us were standing on the opposite side. The president of the board asked for our consent to say the grades out loud and he started telling the grades of the thesis defense and the state exam in the original order. Since I was the first, he said 5 in thesis defense and 5 in state exam and then moved on to the others. Once everyone's grades were told, everyone shook hands and left. A few hours after that, I got a message on Neptun that my student status has been changed to 'Graduated' and my final grade was available on Neptun -> Studies -> Training Data under the Diploma section. 10 days after this, I got my original Degree Certificate and Diploma Supplement. The degree certificate is a single-page document saying you graduated from this university in this course. The diploma supplement includes more detailed information including the transcript of all courses taken.","title":"MY STATE EXAM EXPERIENCE"},{"location":"5_other_tips/","text":"OTHER TIPS Wear complete formals including a tie. Carry your thesis ppt in a USB drive. Carry a pen to the room.","title":"Other Tips"},{"location":"5_other_tips/#other-tips","text":"Wear complete formals including a tie. Carry your thesis ppt in a USB drive. Carry a pen to the room.","title":"OTHER TIPS"},{"location":"6_contributing/","text":"CONTRIBUTE There might be grammatical errors, typos, or missing information (mostly in the electronics, control system and signals and systems based topics), that is why if you spot any such mistake, please make sure to correct it by contributing in these two ways: Contributing directly on GitHub: You can contribute to this project HERE The information is written in simple markdown files found on the main branch in the project_files/docs directory. You can open the markdown file you wish to edit and make the changes. Contributing to a GitHub project is straightforward, if you need help you can refer to THIS ARTICLE If you contribute this way, then your GitHub username will appear as a contributor which is great for your profile. Sending me an email: This method is not preferred but you can send me an email -> veersingh230799@gmail.com and let me know where the mistake is. PS: The typos or errors in the question itself are fine. It is exactly how it was printed on the pdf so it is not changed. If a student tries to copy-paste the entire question, then this website should show up, but if I corrected the typos in the questions, then this would not work.","title":"Contribute"},{"location":"6_contributing/#contribute","text":"There might be grammatical errors, typos, or missing information (mostly in the electronics, control system and signals and systems based topics), that is why if you spot any such mistake, please make sure to correct it by contributing in these two ways: Contributing directly on GitHub: You can contribute to this project HERE The information is written in simple markdown files found on the main branch in the project_files/docs directory. You can open the markdown file you wish to edit and make the changes. Contributing to a GitHub project is straightforward, if you need help you can refer to THIS ARTICLE If you contribute this way, then your GitHub username will appear as a contributor which is great for your profile. Sending me an email: This method is not preferred but you can send me an email -> veersingh230799@gmail.com and let me know where the mistake is. PS: The typos or errors in the question itself are fine. It is exactly how it was printed on the pdf so it is not changed. If a student tries to copy-paste the entire question, then this website should show up, but if I corrected the typos in the questions, then this would not work.","title":"CONTRIBUTE"},{"location":"7_show_your_appreciation/","text":"SHOW YOUR APPRECIATION If you found this helpful, you can: Give the GitHub repository a star. Share with other CSE students or even CS students since they might have some similar questions.","title":"Show Your Appreciation"},{"location":"7_show_your_appreciation/#show-your-appreciation","text":"If you found this helpful, you can: Give the GitHub repository a star. Share with other CSE students or even CS students since they might have some similar questions.","title":"SHOW YOUR APPRECIATION"},{"location":"Question_1/","text":"1. PART 1 The processor implementation options: Processor technology, implementation techniques and design technologies. Typically peripherals for embedded systems. Communication protocols. PART 2 Program units. Subprograms. Parameter evaluation. Parameter passing methods. Block. Scoping, accessibility. Abstract data type. Generic programming. I/O tools of programming languages, file handling. Exception handling. Parallel programming. Part 1 Processor \u2013 A processor or a central processing unit is the electronic circuit that executes instructions in a computer program. The processor performs basic arithmetic, logic control, and input/output operations specified by the instructions in a program. Principal components of a CPU include the arithmetic logic unit (ALU) that performs arithmetic and logic operations, processor registers that supply operands to the ALU and store the results of ALU operations, and a control unit that performs the fetch, decode, and execution cycle. All processors execute a sequence of stored instructions which is called a program. These instructions are kept in the computer memory. The instructions cycle typically comprises fetch, decode, and execute. Fetch involves retrieving the instruction from program memory, which is determined by the program counter. Next comes decode, here the instruction is converted into a signal. Finally, the instruction is executed as a single action or sequence of actions. The results are usually written to the very fast registers on the CPU but sometimes can be written to the slower but much bigger computer memory. Modern CPUs also have cache, which is super-fast memory stored on the CPU, this is much smaller than the main memory, but can be used extremely quickly and thus reduces the time and energy to access data from the main memory. Cache has a hierarchy of where the data is organized called L1, L2, L3, etc. in decreasing speeds and increasing sizes. Most CPUs are synchronous circuits which means they use a clock signal to pace sequential operations. This clock signal is produced by an external oscillator circuit that generates a consistent number of pulses each second in the form of a periodic square wave. The frequency of the clock pulses determines the rate at which a CPU executes instructions, the faster the clock, the more instructions the CPU will execute each second. Microprocessor \u2013 This is a computer processor where the data processing logic and control are included on a single integrated circuit. The microprocessor uses Very-Large-scale Integration to integrate the entire CPU onto a single IC, this greatly reduces the cost of processing power. The first commercially available microprocessor was the intel 4004. Microprocessors are very popular in almost all desktops and some laptops with modern processors like Intel\u2019s alder lake and AMD\u2019s ryzen 5000 using the x86-64 instruction set architecture. Microcontroller \u2013 These are microprocessors along with memory and programmable input/output peripherals. Microcontrollers are designed for embedded applications like single-board computers like the raspberry pi. There are more sophisticated chips called System on a chip or SoC which have a microcontroller as a part but also have graphics processing unit and Wi-Fi modules. These SoCs are often seen in smartphones like the Apple A14 chip or the Qualcomm snapdragon 888 seen in most high-end iPhones and android phones. Implementation \u2013 An instruction set architecture is an abstract model of a computer. A realization of an ISA is called an implementation. Different ISAs vary in performance, efficiency, size, etc. ISA serves as the interface between software and hardware. Software that has been written for an ISA can run on different implementations of the same ISA. This has helped lower the costs of computers and increase their applicability. There are 3 popular ISAs today, x86-64 which was developed by Intel and then AMD. These are complex instruction set computer CISC architecture, which means a single instruction can execute several low-level operations. These are most prevalent on desktops, servers, and laptops. The other very popular ISA is ARM which is developed by Arm Ltd. These are reduced instruction set computer RISC architectures where a given task requires more instructions as compared to CISC, but the individual instructions are simpler and executed faster. ARM chips are also substantially more power-efficient and thus are the primary chips used in smartphones and single-board computers like the raspberry pi. They are also slowly being used for laptops due to their battery performance. The third most popular architecture is RISC-V which in contrast to x86-64 and ARM is open source. This means anyone can use this ISA without any royalties or licensing fees. This is also a RISC-based architecture. Embedded systems are computer systems comprising of a processor, memory, and input/output peripheral devices that have a dedicated function within a larger system. Embedded systems range from simple microcontroller boards like Arduino to more complex systems which use multiple peripherals and networking equipment to communicate with other systems. Typical peripherals for embedded systems are: Serial Communication Interfaces (SCI) \u2013 These are relatively slow, asynchronous communication ports that are used to communicate with other embedded systems and devices. Inter-Integrated Circuit(I2C) \u2013 These are widely used for attaching lower-speed peripheral integrated circuits to processors and microcontrollers in short-distance communication. Universal Serial Bus (USB) \u2013 USB is an industry-standard that allows for connection, communication, and power supply. Embedded systems can use it to power, transfer data, or connect to input devices like keyboards and mice. Multimedia Cards (SD cards) \u2013 These are used to store the data, and, in most cases, they host the operating system for the embedded system. Network (Ethernet) \u2013 Ethernet ports are a family of wired computer networking technologies used to connect multiple devices physically. General Purpose Input/Output (GPIO) \u2013 GPIO is an uncommitted digital signal pin or multiple pins on embedded systems that can be used as an input or output or both and are controlled by the user at runtime. In the case of raspberry pi, we have multiple HATs (hardware attached on top) which connect to the GPIO pins. These can be temperature detection HAT, LED HATs, etc. Communication protocols in embedded systems can be of two kinds \u2013 Inter system protocol and Intra system protocol. Inter System Protocol - This is the communication between two communication devices, for example, a PC and an embedded system. Here communication is achieved through inter bus system. \u25cf USB \u2013 Universal Serial Bus, this is a two-wired serial communication protocol. USB sends and receives the data serially between the host and an external peripheral device. Data is sent as packets. \u25cf UART \u2013 Universal Asynchronous Receiver/Transmitter is a physical piece of hardware that converts parallel data into serial data. Its main purpose is to transmit and receive data serially. \u25cf USART \u2013 Universal Synchronous Asynchronous Receiver/Transmitter is identical to UART with added synchronous functionality. Intra System Protocol \u2013 This establishes communication between components within the circuit board. \u25cf I2C \u2013 Inter-Integrated Circuit is a serial communication protocol. It allows connecting peripheral chips with a microcontroller. \u25cf SPI - Serial Peripheral Interface is a serial communication protocol. It is used for short-distance communication in embedded systems. \u25cf CAN \u2013 Controller Area Network is a serial communication protocol and is based on a message-oriented communication protocol. It is primarily used for communication in embedded systems in vehicles. Part 2 The program unit is a sequence of one or more lines, organized as statements, comments, and includes directives. A program unit can be the main program, a module, a block data program unit, an external function subprogram, or an external subroutine subprogram. A subprogram is a sequence of instructions whose execution is invoked from one or more remote locations in a program, with the expectation that when the subprogram execution is complete, execution resumes at the instruction after the one that invoked the subprogram in high-level languages, subprograms are also called subroutines, procedures, and functions. In object-oriented languages, they are usually called methods or constructors. In most modern high-level languages, subprograms can have parameters, local variables, and returned values. A procedure just executes a set of instructions while a function will return a value when it has finished executing. Writing subprograms makes the code more readable and reusable as the code is broken into smaller sections. Parameter evaluation is the process of mapping formal and actual parameters when a subprogram is called. Formal parameters are defined in the specification of the subprogram, they are declared only once. Actual parameters (arguments) are specified in the calls themselves. Thus, the formal parameter list is determinative to parameter evaluation. There are three issues related to parameter evaluation: Assigning actual parameter to formal parameter \u2013 The actual parameters are assigned to formal parameters based on their relative order in the parameter list, the first argument is assigned to the first formal parameter, second to second, and so on. We can also supply the name of the formal parameter and assign it to the actual parameter, here the order is irrelevant. Number of actual parameters passed to the subprogram call \u2013 The number of formal parameters is fixed; in this case, the number of actual parameters must equal the number of formal parameters, or the number of actual parameters can be less than the number of formal parameters in which case the formal parameters did not assign an actual parameter during the subprogram call will be assigned default values which are pre-defined by the programmer. Relationship between types of formal and actual parameters \u2013 In some programming languages the type of the actual parameter must be exactly as the type of the formal parameter. In other languages, the actual parameter is converted to the type of the corresponding formal parameter. Parameter passing is the action of passing the actual parameters to the formal parameters when a function or subroutine is called. There are various methods to pass parameters: Pass by value \u2013 Here the value of the actual parameters is copied to formal parameters. These two different parameters store the values in separate memory locations. Here we are passing the value and not the variable. Pass by reference \u2013 Here both actual and formal parameters refer to the same memory location. Thus, the changes made to the formal parameters in the subroutine call will cause changes to the actual parameter. Here we are not passing the value but the memory address. Block or code block is a structure of source code that is grouped. Blocks contain one or more declarations and statements. They allow us to group statements so they can be treated as one statement and to define scopes for variables to distinguish them from the same name used elsewhere. The scope is where an item like variable, constant, function, etc that has an identifier name is recognized and be used. These examples use a variable as the item. Global scope is when a variable is defined outside a function, when the program is compiled, this variable is assigned memory space at initialization. This variable can be used for all functions in the source code and even other modules which are linked to the code. Global variables are always defined at the very top before any function definitions, so they are available to all functions. Local scope occurs when a variable is defined inside a function or a code block like an if statement. When the code is compiled, these variables are assigned to the stack in the computer memory, this exists until the function is complete. These variables are assigned at the top inside of the function or code block, making them available to everything inside the function. If a local variable has the same name identifier as a global variable, then that variable will get the local variable value inside the function call. Abstract Data Types or ADT are objects whose behavior is defined by a set of values and a set of operations. ADT only mentions what operations are to be performed but not how these operations will be implemented. It does not specify how data will be organized in memory and what algorithms will be used for implementing the operations. It is called abstract because it gives an implementation-independent view. There are many ADTs like list, stack, and queue, all of these have different implementations in different programming languages. Generic programming is a style of programming where algorithms and functions are written in terms of types so that they work on all data types and not just one. We can have a placeholder data type which is a general data type, this can be replaced with different data types and work with all of them. Computer stores data in files like plain text, image data, etc. Files can be accessed, updated, and created using programming languages. When data is written into a file, that is called input and when data is read from a file, that is called output. Files can be handled in separate ways, read-only mode allows for only getting data from the file. Write only mode allows the programming language to only write data to the file and not read it. Read and write mode allows for both getting data from the file and writing data to the file. Append mode allows for writing the file without overwriting the existing data on the file. All programming languages first initialize an object of the type of file, which contains all the information to control the stream, we also must specify the mode such as read-only, write-only, etc. Once functions associated with the file are done, the file must be closed. Once this is done, the memory allocated for handling the file is freed up. In python a file is opened using the open() function, it can be read using read(), written to using write(), and closed using close() functions of the file object. Exception handling is the process of responding to the occurrence of exceptions or errors during the execution of a program. An exception breaks the normal flow of execution and executes a pre-registered exception handler. Exception handling attempts to handle these situations so that a program does not crash. In python, there are some built-in exception handlers, we can also define custom exception handlers using the \u2018try \u2013 except\u2019 blocks. The program first attempts the try block, if it throws an exception, then we execute the except block, and the program flow is maintained instead of crashing. Parallel programming is when we use multiple processors or threads to execute parts of a program at the same time. The program is broken down into smaller steps, these are then executed simultaneously on multiple threads. The output of these steps mustn't influence each other. This is very advantageous since all modern processors are multi-core with SMT or Simultaneous multithreading enabled which means a single core can perform 2 virtual threads at the same time. This type of programming is hard to learn and to a large extent must be enforced by the programmer during programming.","title":"Question 1"},{"location":"Question_1/#1-part-1-the-processor-implementation-options-processor-technology-implementation-techniques-and-design-technologies-typically-peripherals-for-embedded-systems-communication-protocols-part-2-program-units-subprograms-parameter-evaluation-parameter-passing-methods-block-scoping-accessibility-abstract-data-type-generic-programming-io-tools-of-programming-languages-file-handling-exception-handling-parallel-programming","text":"","title":"1. PART 1 The processor implementation options: Processor technology, implementation techniques and design technologies. Typically peripherals for embedded systems. Communication protocols. PART 2 Program units. Subprograms. Parameter evaluation. Parameter passing methods. Block. Scoping, accessibility. Abstract data type. Generic programming. I/O tools of programming languages, file handling. Exception handling. Parallel programming."},{"location":"Question_1/#part-1","text":"Processor \u2013 A processor or a central processing unit is the electronic circuit that executes instructions in a computer program. The processor performs basic arithmetic, logic control, and input/output operations specified by the instructions in a program. Principal components of a CPU include the arithmetic logic unit (ALU) that performs arithmetic and logic operations, processor registers that supply operands to the ALU and store the results of ALU operations, and a control unit that performs the fetch, decode, and execution cycle. All processors execute a sequence of stored instructions which is called a program. These instructions are kept in the computer memory. The instructions cycle typically comprises fetch, decode, and execute. Fetch involves retrieving the instruction from program memory, which is determined by the program counter. Next comes decode, here the instruction is converted into a signal. Finally, the instruction is executed as a single action or sequence of actions. The results are usually written to the very fast registers on the CPU but sometimes can be written to the slower but much bigger computer memory. Modern CPUs also have cache, which is super-fast memory stored on the CPU, this is much smaller than the main memory, but can be used extremely quickly and thus reduces the time and energy to access data from the main memory. Cache has a hierarchy of where the data is organized called L1, L2, L3, etc. in decreasing speeds and increasing sizes. Most CPUs are synchronous circuits which means they use a clock signal to pace sequential operations. This clock signal is produced by an external oscillator circuit that generates a consistent number of pulses each second in the form of a periodic square wave. The frequency of the clock pulses determines the rate at which a CPU executes instructions, the faster the clock, the more instructions the CPU will execute each second. Microprocessor \u2013 This is a computer processor where the data processing logic and control are included on a single integrated circuit. The microprocessor uses Very-Large-scale Integration to integrate the entire CPU onto a single IC, this greatly reduces the cost of processing power. The first commercially available microprocessor was the intel 4004. Microprocessors are very popular in almost all desktops and some laptops with modern processors like Intel\u2019s alder lake and AMD\u2019s ryzen 5000 using the x86-64 instruction set architecture. Microcontroller \u2013 These are microprocessors along with memory and programmable input/output peripherals. Microcontrollers are designed for embedded applications like single-board computers like the raspberry pi. There are more sophisticated chips called System on a chip or SoC which have a microcontroller as a part but also have graphics processing unit and Wi-Fi modules. These SoCs are often seen in smartphones like the Apple A14 chip or the Qualcomm snapdragon 888 seen in most high-end iPhones and android phones. Implementation \u2013 An instruction set architecture is an abstract model of a computer. A realization of an ISA is called an implementation. Different ISAs vary in performance, efficiency, size, etc. ISA serves as the interface between software and hardware. Software that has been written for an ISA can run on different implementations of the same ISA. This has helped lower the costs of computers and increase their applicability. There are 3 popular ISAs today, x86-64 which was developed by Intel and then AMD. These are complex instruction set computer CISC architecture, which means a single instruction can execute several low-level operations. These are most prevalent on desktops, servers, and laptops. The other very popular ISA is ARM which is developed by Arm Ltd. These are reduced instruction set computer RISC architectures where a given task requires more instructions as compared to CISC, but the individual instructions are simpler and executed faster. ARM chips are also substantially more power-efficient and thus are the primary chips used in smartphones and single-board computers like the raspberry pi. They are also slowly being used for laptops due to their battery performance. The third most popular architecture is RISC-V which in contrast to x86-64 and ARM is open source. This means anyone can use this ISA without any royalties or licensing fees. This is also a RISC-based architecture. Embedded systems are computer systems comprising of a processor, memory, and input/output peripheral devices that have a dedicated function within a larger system. Embedded systems range from simple microcontroller boards like Arduino to more complex systems which use multiple peripherals and networking equipment to communicate with other systems. Typical peripherals for embedded systems are: Serial Communication Interfaces (SCI) \u2013 These are relatively slow, asynchronous communication ports that are used to communicate with other embedded systems and devices. Inter-Integrated Circuit(I2C) \u2013 These are widely used for attaching lower-speed peripheral integrated circuits to processors and microcontrollers in short-distance communication. Universal Serial Bus (USB) \u2013 USB is an industry-standard that allows for connection, communication, and power supply. Embedded systems can use it to power, transfer data, or connect to input devices like keyboards and mice. Multimedia Cards (SD cards) \u2013 These are used to store the data, and, in most cases, they host the operating system for the embedded system. Network (Ethernet) \u2013 Ethernet ports are a family of wired computer networking technologies used to connect multiple devices physically. General Purpose Input/Output (GPIO) \u2013 GPIO is an uncommitted digital signal pin or multiple pins on embedded systems that can be used as an input or output or both and are controlled by the user at runtime. In the case of raspberry pi, we have multiple HATs (hardware attached on top) which connect to the GPIO pins. These can be temperature detection HAT, LED HATs, etc. Communication protocols in embedded systems can be of two kinds \u2013 Inter system protocol and Intra system protocol. Inter System Protocol - This is the communication between two communication devices, for example, a PC and an embedded system. Here communication is achieved through inter bus system. \u25cf USB \u2013 Universal Serial Bus, this is a two-wired serial communication protocol. USB sends and receives the data serially between the host and an external peripheral device. Data is sent as packets. \u25cf UART \u2013 Universal Asynchronous Receiver/Transmitter is a physical piece of hardware that converts parallel data into serial data. Its main purpose is to transmit and receive data serially. \u25cf USART \u2013 Universal Synchronous Asynchronous Receiver/Transmitter is identical to UART with added synchronous functionality. Intra System Protocol \u2013 This establishes communication between components within the circuit board. \u25cf I2C \u2013 Inter-Integrated Circuit is a serial communication protocol. It allows connecting peripheral chips with a microcontroller. \u25cf SPI - Serial Peripheral Interface is a serial communication protocol. It is used for short-distance communication in embedded systems. \u25cf CAN \u2013 Controller Area Network is a serial communication protocol and is based on a message-oriented communication protocol. It is primarily used for communication in embedded systems in vehicles.","title":"Part 1"},{"location":"Question_1/#part-2","text":"The program unit is a sequence of one or more lines, organized as statements, comments, and includes directives. A program unit can be the main program, a module, a block data program unit, an external function subprogram, or an external subroutine subprogram. A subprogram is a sequence of instructions whose execution is invoked from one or more remote locations in a program, with the expectation that when the subprogram execution is complete, execution resumes at the instruction after the one that invoked the subprogram in high-level languages, subprograms are also called subroutines, procedures, and functions. In object-oriented languages, they are usually called methods or constructors. In most modern high-level languages, subprograms can have parameters, local variables, and returned values. A procedure just executes a set of instructions while a function will return a value when it has finished executing. Writing subprograms makes the code more readable and reusable as the code is broken into smaller sections. Parameter evaluation is the process of mapping formal and actual parameters when a subprogram is called. Formal parameters are defined in the specification of the subprogram, they are declared only once. Actual parameters (arguments) are specified in the calls themselves. Thus, the formal parameter list is determinative to parameter evaluation. There are three issues related to parameter evaluation: Assigning actual parameter to formal parameter \u2013 The actual parameters are assigned to formal parameters based on their relative order in the parameter list, the first argument is assigned to the first formal parameter, second to second, and so on. We can also supply the name of the formal parameter and assign it to the actual parameter, here the order is irrelevant. Number of actual parameters passed to the subprogram call \u2013 The number of formal parameters is fixed; in this case, the number of actual parameters must equal the number of formal parameters, or the number of actual parameters can be less than the number of formal parameters in which case the formal parameters did not assign an actual parameter during the subprogram call will be assigned default values which are pre-defined by the programmer. Relationship between types of formal and actual parameters \u2013 In some programming languages the type of the actual parameter must be exactly as the type of the formal parameter. In other languages, the actual parameter is converted to the type of the corresponding formal parameter. Parameter passing is the action of passing the actual parameters to the formal parameters when a function or subroutine is called. There are various methods to pass parameters: Pass by value \u2013 Here the value of the actual parameters is copied to formal parameters. These two different parameters store the values in separate memory locations. Here we are passing the value and not the variable. Pass by reference \u2013 Here both actual and formal parameters refer to the same memory location. Thus, the changes made to the formal parameters in the subroutine call will cause changes to the actual parameter. Here we are not passing the value but the memory address. Block or code block is a structure of source code that is grouped. Blocks contain one or more declarations and statements. They allow us to group statements so they can be treated as one statement and to define scopes for variables to distinguish them from the same name used elsewhere. The scope is where an item like variable, constant, function, etc that has an identifier name is recognized and be used. These examples use a variable as the item. Global scope is when a variable is defined outside a function, when the program is compiled, this variable is assigned memory space at initialization. This variable can be used for all functions in the source code and even other modules which are linked to the code. Global variables are always defined at the very top before any function definitions, so they are available to all functions. Local scope occurs when a variable is defined inside a function or a code block like an if statement. When the code is compiled, these variables are assigned to the stack in the computer memory, this exists until the function is complete. These variables are assigned at the top inside of the function or code block, making them available to everything inside the function. If a local variable has the same name identifier as a global variable, then that variable will get the local variable value inside the function call. Abstract Data Types or ADT are objects whose behavior is defined by a set of values and a set of operations. ADT only mentions what operations are to be performed but not how these operations will be implemented. It does not specify how data will be organized in memory and what algorithms will be used for implementing the operations. It is called abstract because it gives an implementation-independent view. There are many ADTs like list, stack, and queue, all of these have different implementations in different programming languages. Generic programming is a style of programming where algorithms and functions are written in terms of types so that they work on all data types and not just one. We can have a placeholder data type which is a general data type, this can be replaced with different data types and work with all of them. Computer stores data in files like plain text, image data, etc. Files can be accessed, updated, and created using programming languages. When data is written into a file, that is called input and when data is read from a file, that is called output. Files can be handled in separate ways, read-only mode allows for only getting data from the file. Write only mode allows the programming language to only write data to the file and not read it. Read and write mode allows for both getting data from the file and writing data to the file. Append mode allows for writing the file without overwriting the existing data on the file. All programming languages first initialize an object of the type of file, which contains all the information to control the stream, we also must specify the mode such as read-only, write-only, etc. Once functions associated with the file are done, the file must be closed. Once this is done, the memory allocated for handling the file is freed up. In python a file is opened using the open() function, it can be read using read(), written to using write(), and closed using close() functions of the file object. Exception handling is the process of responding to the occurrence of exceptions or errors during the execution of a program. An exception breaks the normal flow of execution and executes a pre-registered exception handler. Exception handling attempts to handle these situations so that a program does not crash. In python, there are some built-in exception handlers, we can also define custom exception handlers using the \u2018try \u2013 except\u2019 blocks. The program first attempts the try block, if it throws an exception, then we execute the except block, and the program flow is maintained instead of crashing. Parallel programming is when we use multiple processors or threads to execute parts of a program at the same time. The program is broken down into smaller steps, these are then executed simultaneously on multiple threads. The output of these steps mustn't influence each other. This is very advantageous since all modern processors are multi-core with SMT or Simultaneous multithreading enabled which means a single core can perform 2 virtual threads at the same time. This type of programming is hard to learn and to a large extent must be enforced by the programmer during programming.","title":"Part 2"},{"location":"Question_10/","text":"10. PART 1 Configuration of a web server using SSL, the OpenSSL cryptographic library: authentication, encryption. PART 2 The instruction set architecture (ISA) of Intel X86 processors (registers, addressing, instructions, memory architecture, interrupt system)","title":"Question 10"},{"location":"Question_10/#10-part-1-configuration-of-a-web-server-using-ssl-the-openssl-cryptographic-library-authentication-encryption-part-2-the-instruction-set-architecture-isa-of-intel-x86-processors-registers-addressing-instructions-memory-architecture-interrupt-system","text":"","title":"10. PART 1 Configuration of a web server using SSL, the OpenSSL cryptographic library: authentication, encryption. PART 2 The instruction set architecture (ISA) of Intel X86 processors (registers, addressing, instructions, memory architecture, interrupt system)"},{"location":"Question_11/","text":"11. PART 1 Interprocess communication (file, signal, pipe, socket) PART 2 Time complexity of algorithms: insertion sort, merge sort, searching in linear and logarithmic time. Quick sort, the minimal number of necessary comparisons. Sorting in linear time: radix sort, bucket sort.","title":"Question 11"},{"location":"Question_11/#11-part-1-interprocess-communication-file-signal-pipe-socket-part-2-time-complexity-of-algorithms-insertion-sort-merge-sort-searching-in-linear-and-logarithmic-time-quick-sort-the-minimal-number-of-necessary-comparisons-sorting-in-linear-time-radix-sort-bucket-sort","text":"","title":"11. PART 1 Interprocess communication (file, signal, pipe, socket) PART 2 Time complexity of algorithms: insertion sort, merge sort, searching in linear and logarithmic time. Quick sort, the minimal number of necessary comparisons. Sorting in linear time: radix sort, bucket sort."},{"location":"Question_12/","text":"12. PART 1 Entity-relationship (ER) model, design with ER diagrams. Relational data model, relation, scheme, attribute. Building up a relational scheme from an ER-diagram. PART 2 Diodes. Rectifiers. DC to DC converters. Voltage regulators. Current regulators.","title":"Question 12"},{"location":"Question_12/#12-part-1-entity-relationship-er-model-design-with-er-diagrams-relational-data-model-relation-scheme-attribute-building-up-a-relational-scheme-from-an-er-diagram-part-2-diodes-rectifiers-dc-to-dc-converters-voltage-regulators-current-regulators","text":"","title":"12. PART 1 Entity-relationship (ER) model, design with ER diagrams. Relational data model, relation, scheme, attribute. Building up a relational scheme from an ER-diagram. PART 2 Diodes. Rectifiers. DC to DC converters. Voltage regulators. Current regulators."},{"location":"Question_13/","text":"13. PART 1 Modern processor solutions (pipeline, hazard, out-of-order execution, speculative execution, superscalar-, VLIW- and vector processors) PART 2 Optimization and evaluation of relational queries. Tree-based optimization in relational algebra. Cost-based optimization.","title":"Question 13"},{"location":"Question_13/#13-part-1-modern-processor-solutions-pipeline-hazard-out-of-order-execution-speculative-execution-superscalar-vliw-and-vector-processors-part-2-optimization-and-evaluation-of-relational-queries-tree-based-optimization-in-relational-algebra-cost-based-optimization","text":"","title":"13. PART 1 Modern processor solutions (pipeline, hazard, out-of-order execution, speculative execution, superscalar-, VLIW- and vector processors) PART 2 Optimization and evaluation of relational queries. Tree-based optimization in relational algebra. Cost-based optimization."},{"location":"Question_14/","text":"14. PART 1 Explain the NAT/PAT address translation mechanisms. PART 2 Basic notions concerning data structures: modelling, abstraction, abstract data types. Elementary data structures: lists, stacks, queues. Sets, multisets, arrays. The representation of trees, tree traversal, deletion and insertion.","title":"Question 14"},{"location":"Question_14/#14-part-1-explain-the-natpat-address-translation-mechanisms-part-2-basic-notions-concerning-data-structures-modelling-abstraction-abstract-data-types-elementary-data-structures-lists-stacks-queues-sets-multisets-arrays-the-representation-of-trees-tree-traversal-deletion-and-insertion","text":"","title":"14. PART 1 Explain the NAT/PAT address translation mechanisms. PART 2 Basic notions concerning data structures: modelling, abstraction, abstract data types. Elementary data structures: lists, stacks, queues. Sets, multisets, arrays. The representation of trees, tree traversal, deletion and insertion."},{"location":"Question_15/","text":"15. PART 1 Basic concepts of object-oriented paradigm. Class, object, instantiation. Inheritance, class hierarchy. Polymorphism, method overloading. Scoping, information hiding, accessibility levels. Abstract classes and interfaces. Class diagram of UML. PART 2 Compare the SNMP and RMON network management systems.","title":"Question 15"},{"location":"Question_15/#15-part-1-basic-concepts-of-object-oriented-paradigm-class-object-instantiation-inheritance-class-hierarchy-polymorphism-method-overloading-scoping-information-hiding-accessibility-levels-abstract-classes-and-interfaces-class-diagram-of-uml-part-2-compare-the-snmp-and-rmon-network-management-systems","text":"","title":"15. PART 1 Basic concepts of object-oriented paradigm. Class, object, instantiation. Inheritance, class hierarchy. Polymorphism, method overloading. Scoping, information hiding, accessibility levels. Abstract classes and interfaces. Class diagram of UML. PART 2 Compare the SNMP and RMON network management systems."},{"location":"Question_2/","text":"2. PART 1 Synthesis of continuous time control systems. The gain and phase margin. Linear systems and their description in time- and frequency domains. Signal transfer in control systems. PART 2 Explain the data elements of TCP and UDP transport layer protocols, and the differences between their mechanisms. Part 1 A control system is a system that provides the desired response by controlling the output. The input is varied by some mechanism. The traffic lights control system is an example of a control system. A sequence of input signals is applied, and the output is one of the three lights that stay on for some duration of time. Based on the traffic data at a particular junction, the on and off times of the lights can be determined. The input signal controls the output, and it operates on a time basis. Control systems can be classified on the type of signal. A system that deals with continuous-time signals is called a continuous-time system; its opposite is the discrete-time system which uses discrete-time signals. Continuous-time systems view variables as having a particular value for potentially only an infinitesimally short amount of time. The variable time ranges over the entire real number line. Its domain is a continuum, that is the function's domain is an uncountable set. Gain and Phase margin can be derived from a Bode plot. A bode plot is a graph that is used to determine the stability of a control system. It maps the frequency response of the system through two graphs \u2013 the bode magnitude plot (expressing the magnitude in decibels) and the bode phase plot (expressing the phase shift in degrees). The Gain Margin (GM) is the amount of gain which can be increased or decreased without making the system unstable. It is expressed as a magnitude in decibels. The greater the gain margin, the greater the stability of a system. GM can be read directly from a bode plot, this is done by calculating the vertical distance between the magnitude curve and the x-axis at the frequency, this point is known as the phase crossover frequency. The gain margin is the negative of gain. If the gain is 20 then the gain margin is -20 decibels. Phase Margin (PM) is the amount of phase which can be increased or decreased without making the system unstable. It is expressed as the phase in degrees. The greater the phase margin, the greater the stability of the system. We can read the phase margin directly from a bode plot. This is done by calculating the vertical distance between the phase curve and the x-axis at the frequency. This point is known as the gain crossover frequency. Phase margin is the phase lag plus 180 degrees. If the phase lag is -189 degrees, then the phase margin is -9 degrees. Linear systems are systems whose outputs for a linear combination of inputs are the same as a linear combination of individual responses to those inputs. Linear systems can be time-invariant which are linear systems where the output does not depend on when input was applied. So, if we apply an input to a system now or T seconds from now, the output will be identical except for a time delay of T seconds. Linear systems in frequency domains refer to the analysis of these systems with respect to frequency. A frequency-domain graph shows how much of the signal lies within each given frequency band over a range of frequencies. To change a linear system from a time domain to a frequency domain, we apply a Laplace transform function of the impulse response. In the frequency domain, the output is the product of the transfer function with the transformed input. Transfer function represents the relationship between the output signal of a control system and the input signal for all possible input values. For any control system, there is a reference input known as excitation which operates through a transfer function to produce a controlled output. The transfer function of a control system is defined as the ratio of the Laplace transform of the output variable to the Laplace transform of the input variable assuming all initial conditions to be zero. It is not necessary that the output and input of a control system are of the same category. For example, in electric motors, the input is an electrical signal whereas the output is a mechanical signal since electrical energy is required to rotate the motors. Similarly in an electric generator, the input is a mechanical signal, and the output is an electrical signal since mechanical energy is required to produce electricity in a generator. But for mathematical analysis of a system, all kinds of signals should be represented in a similar form. This is done by transforming all kinds of signals to their Laplace form. Transfer functions can be obtained using a Block diagram method or a signal flow graph. The Block diagram method is when the transfer function of each element of a control system is represented by a block diagram. A modified form of a block diagram is a signal flow graph which further shortens the representation of a control system. Poles of a transfer function are defined as those values in the ratio whose substitution in the denominator makes the transfer function infinite. Zeros of transfer function have to do with the numerator. Those values of the ratio that when substituted make the transfer function zero is the zeros of the transfer function. The steps to calculate the transfer function are as follows: The time-domain equations of the system must be written after considering different required variables in the system. Consider the initial conditions as 0, write the Laplace transform of the time domain equations of the system. Determine the input as well as the output variables from the frequency domain equations. Remove the initially considered variables and write the resultant equations in the form of input and output variables. The ratio of Laplace transform of output and input must be determined to have the transfer function of the overall system. Part 2 TCP stands for Transmission Control Protocol, which is a communications standard that enables applications, programs, and computing devices to exchange messages over a network. It is designed to send packets across the internet and ensure the successful delivery of data and messages over networks. TCP guarantees the integrity of the data being communicated over a network. High-level protocols like File Transfer Protocol (FTP), Secure Shell (SSH), Telnet, Internet Message Access Protocol (IMAP), and Simple Mail Transfer Protocol (SMTP) all use TCP. TCP is an expensive protocol since a connection is established between the server and the client. Three-way handshake and error detection add to reliability but increase latency. TCP accepts data from a data stream, divides it into chunks, and adds a TCP header creating a TCP segment. The TCP segment is then encapsulated into an Internet Protocol datagram and exchanged with peers. A TCP segment consists of a segment header and a data section. The segment header contains 10 mandatory fields and an optional extension field. The data sections follow the header and are the actual data carried for the application. The sections are: Source port (16 bits) \u2013 The client\u2019s port number. Destination port (16 bits) \u2013 The server\u2019s port number. Sequence number (32 bits) \u2013 A sequence number used for guaranteeing packet order. Acknowledgment Number (32 bits) \u2013 An acknowledge number notifying senders of the receipt of TCP segments. Data offset (4 bits) \u2013 The size of the TCP header. Reserved (3 bits) \u2013 Set to zero, reserved for future use. Flags (9 bits) \u2013 Flags set TCP control options used to alter the connection. Window (16 bits) \u2013 The receive window. The number of bytes that the sender of this segment is willing to receive. Checksum (16 bits) \u2013 A 16-bit checksum used for error-checking. Urgent pointer (16 bits) \u2013 If the sender sets the URG flag, then this 16-bit field is an offset from the sequence number indicating the last urgent data byte. Options (0-320 bits [divisible by 32]) Padding (0-320 bits [divisible by 32]) - Zeros, ensures that the TCP header ends, and data begins on a 32-bit boundary. Data (variable) \u2013 The payload data for this TCP segment. TCP uses a three-way handshake to establish the connection. First, the client will generate a random number and set it as the sequence number and set the SYN or synchronization bit on, and send this to the server. The server will send a message back to the client, the SYN bit will be on and the ACK or acknowledge bit will be set to the sequence number the client sent plus one. The server will generate its sequence number and send it as well. In the last step, the client sends a message to the server, this time the SYN bit is 0, the acknowledgment number is the sequence number of the server plus one and the sequence number is the acknowledgment number sent by the server in the last step which is the sequence number of the client in the first step plus one. After the handshake is complete, a client can start sending data packets immediately. TCP segments are exchanged between the client and the server. To guard against the unreliable network, TCP uses sequence numbers to verify the correct delivery and ordering of TCP segments. The sequence number is included on each transmitted packet and acknowledged by the opposite host as an acknowledgment number to inform the sending host that the transmitted data was received successfully. Flow control can be managed by the window field, if a sender is under heavy load, then it sets the window to a low value to decrease pressure and vice versa. UDP is User Datagram Protocol is a communications protocol that is primarily used to establish low-latency and loss tolerating connections between applications on the internet. UDP speeds up transmissions by enabling the transfer of data before an agreement is provided by the receiver. As a result, UDP is good for time-sensitive communication like voice over IP (VoIP) and domain name system DNS lookup. UDP sends messages as datagrams and doesn\u2019t provide any guarantee that the data will be delivered or checked for dropped data. UDP allows for packets to be dropped and received in a different order than they were transmitted, making it have low latency. It can be used where many clients are connected, and real-time error correction isn\u2019t necessary such as gaming. UDP header has 4 fields, each of 2 bytes: Source port number \u2013 the port number of the sender. Destination port number \u2013 the destination port number. Length \u2013 the length in bytes of the UDP header and any encapsulated data. Checksum \u2013 used for error checking, it is required in IPv6 and optional in IPv4. Differences between UDP and TCP: UDP is a connectionless protocol whereas TCP is a connection-oriented protocol. UDP is used for VoIP, gaming, live broadcasts whereas TCP is used for most data protocols on the internet. UDP is faster and uses fewer resources whereas TCP has higher latency and is resource-intensive. The packets in UDP don\u2019t necessarily arrive in order, whereas the TCP ensures packet order so they can be stitched back together. UDP allows for missing packets, the sender is unable to know whether a packet was successfully received or not, whereas TCP guarantees no missing packets, and all sent data makes it to the intended recipient. There is basic error checking mechanisms in UDP whereas there is extensive error checking and acknowledgment of data. UDP supports broadcasting whereas TCP does not. UDP is better suited for time-sensitive applications whereas TCP is better suited for applications that need data reliability and are not as time sensitive. UDP has a smaller header than TCP.","title":"Question 2"},{"location":"Question_2/#2-part-1-synthesis-of-continuous-time-control-systems-the-gain-and-phase-margin-linear-systems-and-their-description-in-time-and-frequency-domains-signal-transfer-in-control-systemspart-2-explain-the-data-elements-of-tcp-and-udp-transport-layer-protocols-and-the-differences-between-their-mechanisms","text":"","title":"2. PART 1 Synthesis of continuous time control systems. The gain and phase margin. Linear systems and their description in time- and frequency domains. Signal transfer in control systems.PART 2 Explain the data elements of TCP and UDP transport layer protocols, and the differences between their mechanisms."},{"location":"Question_2/#part-1","text":"A control system is a system that provides the desired response by controlling the output. The input is varied by some mechanism. The traffic lights control system is an example of a control system. A sequence of input signals is applied, and the output is one of the three lights that stay on for some duration of time. Based on the traffic data at a particular junction, the on and off times of the lights can be determined. The input signal controls the output, and it operates on a time basis. Control systems can be classified on the type of signal. A system that deals with continuous-time signals is called a continuous-time system; its opposite is the discrete-time system which uses discrete-time signals. Continuous-time systems view variables as having a particular value for potentially only an infinitesimally short amount of time. The variable time ranges over the entire real number line. Its domain is a continuum, that is the function's domain is an uncountable set. Gain and Phase margin can be derived from a Bode plot. A bode plot is a graph that is used to determine the stability of a control system. It maps the frequency response of the system through two graphs \u2013 the bode magnitude plot (expressing the magnitude in decibels) and the bode phase plot (expressing the phase shift in degrees). The Gain Margin (GM) is the amount of gain which can be increased or decreased without making the system unstable. It is expressed as a magnitude in decibels. The greater the gain margin, the greater the stability of a system. GM can be read directly from a bode plot, this is done by calculating the vertical distance between the magnitude curve and the x-axis at the frequency, this point is known as the phase crossover frequency. The gain margin is the negative of gain. If the gain is 20 then the gain margin is -20 decibels. Phase Margin (PM) is the amount of phase which can be increased or decreased without making the system unstable. It is expressed as the phase in degrees. The greater the phase margin, the greater the stability of the system. We can read the phase margin directly from a bode plot. This is done by calculating the vertical distance between the phase curve and the x-axis at the frequency. This point is known as the gain crossover frequency. Phase margin is the phase lag plus 180 degrees. If the phase lag is -189 degrees, then the phase margin is -9 degrees. Linear systems are systems whose outputs for a linear combination of inputs are the same as a linear combination of individual responses to those inputs. Linear systems can be time-invariant which are linear systems where the output does not depend on when input was applied. So, if we apply an input to a system now or T seconds from now, the output will be identical except for a time delay of T seconds. Linear systems in frequency domains refer to the analysis of these systems with respect to frequency. A frequency-domain graph shows how much of the signal lies within each given frequency band over a range of frequencies. To change a linear system from a time domain to a frequency domain, we apply a Laplace transform function of the impulse response. In the frequency domain, the output is the product of the transfer function with the transformed input. Transfer function represents the relationship between the output signal of a control system and the input signal for all possible input values. For any control system, there is a reference input known as excitation which operates through a transfer function to produce a controlled output. The transfer function of a control system is defined as the ratio of the Laplace transform of the output variable to the Laplace transform of the input variable assuming all initial conditions to be zero. It is not necessary that the output and input of a control system are of the same category. For example, in electric motors, the input is an electrical signal whereas the output is a mechanical signal since electrical energy is required to rotate the motors. Similarly in an electric generator, the input is a mechanical signal, and the output is an electrical signal since mechanical energy is required to produce electricity in a generator. But for mathematical analysis of a system, all kinds of signals should be represented in a similar form. This is done by transforming all kinds of signals to their Laplace form. Transfer functions can be obtained using a Block diagram method or a signal flow graph. The Block diagram method is when the transfer function of each element of a control system is represented by a block diagram. A modified form of a block diagram is a signal flow graph which further shortens the representation of a control system. Poles of a transfer function are defined as those values in the ratio whose substitution in the denominator makes the transfer function infinite. Zeros of transfer function have to do with the numerator. Those values of the ratio that when substituted make the transfer function zero is the zeros of the transfer function. The steps to calculate the transfer function are as follows: The time-domain equations of the system must be written after considering different required variables in the system. Consider the initial conditions as 0, write the Laplace transform of the time domain equations of the system. Determine the input as well as the output variables from the frequency domain equations. Remove the initially considered variables and write the resultant equations in the form of input and output variables. The ratio of Laplace transform of output and input must be determined to have the transfer function of the overall system.","title":"Part 1"},{"location":"Question_2/#part-2","text":"TCP stands for Transmission Control Protocol, which is a communications standard that enables applications, programs, and computing devices to exchange messages over a network. It is designed to send packets across the internet and ensure the successful delivery of data and messages over networks. TCP guarantees the integrity of the data being communicated over a network. High-level protocols like File Transfer Protocol (FTP), Secure Shell (SSH), Telnet, Internet Message Access Protocol (IMAP), and Simple Mail Transfer Protocol (SMTP) all use TCP. TCP is an expensive protocol since a connection is established between the server and the client. Three-way handshake and error detection add to reliability but increase latency. TCP accepts data from a data stream, divides it into chunks, and adds a TCP header creating a TCP segment. The TCP segment is then encapsulated into an Internet Protocol datagram and exchanged with peers. A TCP segment consists of a segment header and a data section. The segment header contains 10 mandatory fields and an optional extension field. The data sections follow the header and are the actual data carried for the application. The sections are: Source port (16 bits) \u2013 The client\u2019s port number. Destination port (16 bits) \u2013 The server\u2019s port number. Sequence number (32 bits) \u2013 A sequence number used for guaranteeing packet order. Acknowledgment Number (32 bits) \u2013 An acknowledge number notifying senders of the receipt of TCP segments. Data offset (4 bits) \u2013 The size of the TCP header. Reserved (3 bits) \u2013 Set to zero, reserved for future use. Flags (9 bits) \u2013 Flags set TCP control options used to alter the connection. Window (16 bits) \u2013 The receive window. The number of bytes that the sender of this segment is willing to receive. Checksum (16 bits) \u2013 A 16-bit checksum used for error-checking. Urgent pointer (16 bits) \u2013 If the sender sets the URG flag, then this 16-bit field is an offset from the sequence number indicating the last urgent data byte. Options (0-320 bits [divisible by 32]) Padding (0-320 bits [divisible by 32]) - Zeros, ensures that the TCP header ends, and data begins on a 32-bit boundary. Data (variable) \u2013 The payload data for this TCP segment. TCP uses a three-way handshake to establish the connection. First, the client will generate a random number and set it as the sequence number and set the SYN or synchronization bit on, and send this to the server. The server will send a message back to the client, the SYN bit will be on and the ACK or acknowledge bit will be set to the sequence number the client sent plus one. The server will generate its sequence number and send it as well. In the last step, the client sends a message to the server, this time the SYN bit is 0, the acknowledgment number is the sequence number of the server plus one and the sequence number is the acknowledgment number sent by the server in the last step which is the sequence number of the client in the first step plus one. After the handshake is complete, a client can start sending data packets immediately. TCP segments are exchanged between the client and the server. To guard against the unreliable network, TCP uses sequence numbers to verify the correct delivery and ordering of TCP segments. The sequence number is included on each transmitted packet and acknowledged by the opposite host as an acknowledgment number to inform the sending host that the transmitted data was received successfully. Flow control can be managed by the window field, if a sender is under heavy load, then it sets the window to a low value to decrease pressure and vice versa. UDP is User Datagram Protocol is a communications protocol that is primarily used to establish low-latency and loss tolerating connections between applications on the internet. UDP speeds up transmissions by enabling the transfer of data before an agreement is provided by the receiver. As a result, UDP is good for time-sensitive communication like voice over IP (VoIP) and domain name system DNS lookup. UDP sends messages as datagrams and doesn\u2019t provide any guarantee that the data will be delivered or checked for dropped data. UDP allows for packets to be dropped and received in a different order than they were transmitted, making it have low latency. It can be used where many clients are connected, and real-time error correction isn\u2019t necessary such as gaming. UDP header has 4 fields, each of 2 bytes: Source port number \u2013 the port number of the sender. Destination port number \u2013 the destination port number. Length \u2013 the length in bytes of the UDP header and any encapsulated data. Checksum \u2013 used for error checking, it is required in IPv6 and optional in IPv4. Differences between UDP and TCP: UDP is a connectionless protocol whereas TCP is a connection-oriented protocol. UDP is used for VoIP, gaming, live broadcasts whereas TCP is used for most data protocols on the internet. UDP is faster and uses fewer resources whereas TCP has higher latency and is resource-intensive. The packets in UDP don\u2019t necessarily arrive in order, whereas the TCP ensures packet order so they can be stitched back together. UDP allows for missing packets, the sender is unable to know whether a packet was successfully received or not, whereas TCP guarantees no missing packets, and all sent data makes it to the intended recipient. There is basic error checking mechanisms in UDP whereas there is extensive error checking and acknowledgment of data. UDP supports broadcasting whereas TCP does not. UDP is better suited for time-sensitive applications whereas TCP is better suited for applications that need data reliability and are not as time sensitive. UDP has a smaller header than TCP.","title":"Part 2"},{"location":"Question_3/","text":"3. PART 1 Combinational logic design. Multiplexers/Demultiplexers. Encoders/Decoders. Comparators. Parity generators/checkers. Arithmetical logical units. PART 2 Present the general problem solving methods and compare them with the methods for solving constraint satisfaction problems. Part 1 Combinational Logic is a type of digital logic that is implemented by Boolean circuits, where the output is a pure function of the present input only. This contrasts with sequential logic, in which the output depends not only on the present input but also on the history of the input, thus sequential logic has memory while combinational logic does not. Combinational logic is used in computer circuits to perform Boolean algebra on input signals and stored data. Computers contain lots of elements that are made using combinational logic like multiplexers, demultiplexers, encoders, decoders, comparators, arithmetic logic units, etc. These circuits are made up of basic NAND, NOR, or NOT gates that are combined or connected to produce more complicated circuits. We have three main ways of specifying the function of a combinational logic circuit: Boolean Algebra \u2013 This is the algebraic expression showing the operation of the logic circuit for each input variable either True or False. Truth Table \u2013 A truth table defines all outputs of a logic gate for given input combinations. Logic Diagram \u2013 This is a graphical representation of the logic circuit that shows the wiring and connections of each logic gate. Multiplexers or MUX are combinational logic circuits that take in several analogs or digital input signals and output only one. The selection is managed by a separate set of digital inputs known as select lines. It can have a maximum of 2n data inputs, n selection lines, and a single output line. One of these data inputs is connected to the output line. In a 4x1 multiplexer, we have 4 data inputs, 2 selection lines, and 1 output. We can construct a truth table of the selection line values, we will have 4 such combinations for both values of each selection line, these 4 combinations will each refer to one of the 4 data inputs. MUX is used in communication systems and computer memory. Demultiplexers or demux are combinational logic circuits that can distribute multiple outputs from a single input. A demux has one input, n number of output lines, m number of control lines and it should conform to n = 2m. In a 1 to 4 demux, we have 1 input, 4 outputs, and 2 control bits. As we have 4 different Boolean combinations for the control bits, these will dictate which of the 4 outputs is used. Demux is used in the arithmetic logic unit and serial to parallel converters. Encoders are combinational logic circuits that convert binary information in the form of 2n input lines into n output lines. For example, we have octal to binary encoder. This takes in 8 input lines and generates 3 output lines, where n = 3. We have a special encoder called the priority encoder which compresses the multiple binary input into a small number of outputs. Encoders are used to translate decimal values to binary for operations like addition, subtraction. Priority encoders are used to detect interrupts in microprocessors applications. Decoders are combinational logic circuits that do the opposite job of encoders. It converts n lines of input into 2n lines of output. For example, we have a 3 to 8 decoder where n = 3. Decoders are used in code conversions, in high-performance memory systems, and for data distribution. Digital comparators are electronic devices that take two numbers as input in binary form and determine whether one number is greater than, less than, or equal to the other number. Comparators are used in microprocessors and microcontrollers. These are made up of AND, NOR, and NOT gates. A 1-bit digital comparator is the simplest digital comparator, it can compare 2 inputs of 1 bit each. We can formulate a truth table that compares these 2 bits. Parity generators are used for error detection during data transmission. When data is transmitted, there may be noise that can change a 1 to 0 or a 0 to a 1. The parity bit is added to the data to make the 1s either even or odd. At the receiving end, the number of 1s is counted and if it doesn\u2019t match with the transmitted data, then it means there is an error in the data. A parity generator is a combinational logic circuit that generates the parity bit in the transmitter. On the receiving end, we have a parity checker which checks the parity. A combination of parity generators and parity checkers is used in digital systems to detect single-bit errors in transmitted data. In even parity, the parity bit will make the total number of 1s an even number, and for odd parity, it will do the same, but the sum will be odd. These errors can be detected and corrected using exclusive OR gates. In a combinational circuit that accepts n-1 bit data, it generates a parity bit which is added to the bitstream. In an even parity bit scheme, the parity bit is 0, if there are an even number of 1s and 1 if there are odd number of 1s. For example: if we want to transmit a 3-bit message with an even parity bit, we have 4 bits in total, A, B, C, and P is the parity bit. We can formulate a truth table with 8 different combinations of A, B, C, for half of the P will be 0 and for the other half, it will be 1. Arithmetic Logic Unit or ALU is a combinational logic circuit that performs arithmetic and bitwise operations on integer binary numbers. This contrasts with the floating-point unit which operates on floating-point numbers or decimals. The inputs to an ALU are the data to be operated on called the operands and a code indicating the operation to be performed. The output is the result of the performed operation on the operands. Many ALU designs, also have status inputs or outputs which convey information about a previous operation or the current operation between ALU and an external status register. Basic ALU has three parallel data buses consisting of two input operands and result output. The opcode is a parallel bus that conveys the ALU an operation selection code. Part 2 Problem-solving is the method to reach the desired goal or find a solution to a given situation. In computer science, problem-solving refers to artificial intelligence techniques using efficient algorithms, heuristics, etc. to find solutions. Some general problem-solving methods are: Heuristics \u2013 This type of method understands the problem and finds a solution based on experimental and trial and error methods. However, these heuristics do not often find the best optimal solution to a specific problem, instead, these offer quick and efficient solutions to attain immediate goals. Since this method is fast and efficient but has lower inaccuracy, it can be combined with optimization algorithms to increase the accuracy of this method. An example of such a problem is the traveling salesman problem where we have a list of cities and their distances, the user must find the optimal route for the salesman to visit every city and return to the starting city. Using a greedy algorithm, we pick the next best step on every current city. Searching Algorithms \u2013 Searching is a very common method of solving a problem. Rational agents use these searching algorithms to find optimal solutions. These agents are goal-based and use atomic representation. These algorithms base the quality of the solution by keeping in mind optimality, time complexity, and space complexity. There are two main types of search algorithms: a. Informed Search \u2013 These algorithms use basic domain knowledge and understand the available information. They use this as a guideline for optimal solutions. These are more efficient solutions than uninformed searches. Some examples are Greedy search and A* search. A greedy algorithm for example finds the optimal choice at each stage, intending to find the global optimal eventually, if we are at a node with 3 possible paths, this algorithm will choose the node with the lowest cost without caring about the overall system. An example is Dijkstra\u2019s algorithm which is a pathfinding algorithm. b. Uninformed Search \u2013 These algorithms do not have the basic domain knowledge. It contains information regarding traversing a tree and identifying lead and goal nodes. The search goes through every node till reaching the desired destination. Some examples are Breadth-first search, Depth-first search, Uniform cost search, etc. In depth-first search, we traverse a given node till its deepest node, then we go back and on to the next node, we do not go to the next node until we have traversed all child nodes of the node we are on. In breadth-first search, we traverse all nodes on a given level before moving to a deeper level. Constraint Satisfaction Problems or CSP can be used to solve a variety of problems more efficiently. A CSP consists of three components, which are variables that are denoted with a V, domains of those variables which are denoted with a D, and constraints that are denoted with a C. In general, problems we try to represent them as states, we move ahead to different states and try to solve those problems, in a CSP we use these 3 components, V, D, and C. V is the set of variables, this is a finite set, for example, we might have variables like V1, V2, all the way till Vn. D is the set of domains; these are also finite and there is one domain for each variable. An example of a set of domains can be D1, D2, all the way till Dn. The domain of a variable is all set of values that the variable can take, this can be a real number, imaginary number, a color, or anything. C is the set of constraints that specify the allowable combination of values. C is represented as Ci which is a tuple of two elements, scope, and relation. Ci = (scope, relation). The scope is the variables we are currently dealing with, and the relationship defines the relationship between the variables in the scope. For this example, let us assume the score is binary, which means the scope contains two variables, let\u2019s say V1 and V2. Now the relationship can be any relationship between these two variables in the scope, let\u2019s say V1 cannot be equal to V2. This relationship is our constraints applied to these two values, so in this example, V1 and V2 can take values from their domain where they do not equal each other, if the domain is a set of all integers from and including 1 to 3, then one valid case could be that V1=1 and V2=2, and an invalid case could be that V1=1 and V2=1. In a constraints satisfaction problem, we have multiple such relationships between many combinations of variables. A CSP is considered solved when all variables have a value assigned to them from the domain with no conflicts of constraints. An example of a CSP is sudoku. In sudoku we have a grid of 9x9, thus we have 81 different variables, we have some pre-filled values, for example, if we have sudoku with 11 filled values, then the set of variables contains 70 elements for each infilled box, the set of domain will be all values each box can take, which is a set consisting of the numbers 1,2,3,4,5,6,7,8,9. Finally, the constraint is that no element can be rotated in its row and column. Using a CSP algorithm like the Arc Consistency algorithm #3 or AC3, we can solve this problem. Another example of a CSP is the fa Australia map coloring problem, where we have to color the 7 regions of Australia, thus the variables are the set of all 7 regions, we can only choose from 3 colors, red, green, and blue, thus the set of the domain contains these 3 colors. Finally, the constraint is that no two neighboring regions can have the same color.","title":"Question 3"},{"location":"Question_3/#3-part-1-combinational-logic-design-multiplexersdemultiplexers-encodersdecoders-comparators-parity-generatorscheckers-arithmetical-logical-units-part-2-present-the-general-problem-solving-methods-and-compare-them-with-the-methods-for-solving-constraint-satisfaction-problems","text":"","title":"3. PART 1 Combinational logic design. Multiplexers/Demultiplexers. Encoders/Decoders. Comparators. Parity generators/checkers. Arithmetical logical units. PART 2 Present the general problem solving methods and compare them with the methods for solving constraint satisfaction problems."},{"location":"Question_3/#part-1","text":"Combinational Logic is a type of digital logic that is implemented by Boolean circuits, where the output is a pure function of the present input only. This contrasts with sequential logic, in which the output depends not only on the present input but also on the history of the input, thus sequential logic has memory while combinational logic does not. Combinational logic is used in computer circuits to perform Boolean algebra on input signals and stored data. Computers contain lots of elements that are made using combinational logic like multiplexers, demultiplexers, encoders, decoders, comparators, arithmetic logic units, etc. These circuits are made up of basic NAND, NOR, or NOT gates that are combined or connected to produce more complicated circuits. We have three main ways of specifying the function of a combinational logic circuit: Boolean Algebra \u2013 This is the algebraic expression showing the operation of the logic circuit for each input variable either True or False. Truth Table \u2013 A truth table defines all outputs of a logic gate for given input combinations. Logic Diagram \u2013 This is a graphical representation of the logic circuit that shows the wiring and connections of each logic gate. Multiplexers or MUX are combinational logic circuits that take in several analogs or digital input signals and output only one. The selection is managed by a separate set of digital inputs known as select lines. It can have a maximum of 2n data inputs, n selection lines, and a single output line. One of these data inputs is connected to the output line. In a 4x1 multiplexer, we have 4 data inputs, 2 selection lines, and 1 output. We can construct a truth table of the selection line values, we will have 4 such combinations for both values of each selection line, these 4 combinations will each refer to one of the 4 data inputs. MUX is used in communication systems and computer memory. Demultiplexers or demux are combinational logic circuits that can distribute multiple outputs from a single input. A demux has one input, n number of output lines, m number of control lines and it should conform to n = 2m. In a 1 to 4 demux, we have 1 input, 4 outputs, and 2 control bits. As we have 4 different Boolean combinations for the control bits, these will dictate which of the 4 outputs is used. Demux is used in the arithmetic logic unit and serial to parallel converters. Encoders are combinational logic circuits that convert binary information in the form of 2n input lines into n output lines. For example, we have octal to binary encoder. This takes in 8 input lines and generates 3 output lines, where n = 3. We have a special encoder called the priority encoder which compresses the multiple binary input into a small number of outputs. Encoders are used to translate decimal values to binary for operations like addition, subtraction. Priority encoders are used to detect interrupts in microprocessors applications. Decoders are combinational logic circuits that do the opposite job of encoders. It converts n lines of input into 2n lines of output. For example, we have a 3 to 8 decoder where n = 3. Decoders are used in code conversions, in high-performance memory systems, and for data distribution. Digital comparators are electronic devices that take two numbers as input in binary form and determine whether one number is greater than, less than, or equal to the other number. Comparators are used in microprocessors and microcontrollers. These are made up of AND, NOR, and NOT gates. A 1-bit digital comparator is the simplest digital comparator, it can compare 2 inputs of 1 bit each. We can formulate a truth table that compares these 2 bits. Parity generators are used for error detection during data transmission. When data is transmitted, there may be noise that can change a 1 to 0 or a 0 to a 1. The parity bit is added to the data to make the 1s either even or odd. At the receiving end, the number of 1s is counted and if it doesn\u2019t match with the transmitted data, then it means there is an error in the data. A parity generator is a combinational logic circuit that generates the parity bit in the transmitter. On the receiving end, we have a parity checker which checks the parity. A combination of parity generators and parity checkers is used in digital systems to detect single-bit errors in transmitted data. In even parity, the parity bit will make the total number of 1s an even number, and for odd parity, it will do the same, but the sum will be odd. These errors can be detected and corrected using exclusive OR gates. In a combinational circuit that accepts n-1 bit data, it generates a parity bit which is added to the bitstream. In an even parity bit scheme, the parity bit is 0, if there are an even number of 1s and 1 if there are odd number of 1s. For example: if we want to transmit a 3-bit message with an even parity bit, we have 4 bits in total, A, B, C, and P is the parity bit. We can formulate a truth table with 8 different combinations of A, B, C, for half of the P will be 0 and for the other half, it will be 1. Arithmetic Logic Unit or ALU is a combinational logic circuit that performs arithmetic and bitwise operations on integer binary numbers. This contrasts with the floating-point unit which operates on floating-point numbers or decimals. The inputs to an ALU are the data to be operated on called the operands and a code indicating the operation to be performed. The output is the result of the performed operation on the operands. Many ALU designs, also have status inputs or outputs which convey information about a previous operation or the current operation between ALU and an external status register. Basic ALU has three parallel data buses consisting of two input operands and result output. The opcode is a parallel bus that conveys the ALU an operation selection code.","title":"Part 1"},{"location":"Question_3/#part-2","text":"Problem-solving is the method to reach the desired goal or find a solution to a given situation. In computer science, problem-solving refers to artificial intelligence techniques using efficient algorithms, heuristics, etc. to find solutions. Some general problem-solving methods are: Heuristics \u2013 This type of method understands the problem and finds a solution based on experimental and trial and error methods. However, these heuristics do not often find the best optimal solution to a specific problem, instead, these offer quick and efficient solutions to attain immediate goals. Since this method is fast and efficient but has lower inaccuracy, it can be combined with optimization algorithms to increase the accuracy of this method. An example of such a problem is the traveling salesman problem where we have a list of cities and their distances, the user must find the optimal route for the salesman to visit every city and return to the starting city. Using a greedy algorithm, we pick the next best step on every current city. Searching Algorithms \u2013 Searching is a very common method of solving a problem. Rational agents use these searching algorithms to find optimal solutions. These agents are goal-based and use atomic representation. These algorithms base the quality of the solution by keeping in mind optimality, time complexity, and space complexity. There are two main types of search algorithms: a. Informed Search \u2013 These algorithms use basic domain knowledge and understand the available information. They use this as a guideline for optimal solutions. These are more efficient solutions than uninformed searches. Some examples are Greedy search and A* search. A greedy algorithm for example finds the optimal choice at each stage, intending to find the global optimal eventually, if we are at a node with 3 possible paths, this algorithm will choose the node with the lowest cost without caring about the overall system. An example is Dijkstra\u2019s algorithm which is a pathfinding algorithm. b. Uninformed Search \u2013 These algorithms do not have the basic domain knowledge. It contains information regarding traversing a tree and identifying lead and goal nodes. The search goes through every node till reaching the desired destination. Some examples are Breadth-first search, Depth-first search, Uniform cost search, etc. In depth-first search, we traverse a given node till its deepest node, then we go back and on to the next node, we do not go to the next node until we have traversed all child nodes of the node we are on. In breadth-first search, we traverse all nodes on a given level before moving to a deeper level. Constraint Satisfaction Problems or CSP can be used to solve a variety of problems more efficiently. A CSP consists of three components, which are variables that are denoted with a V, domains of those variables which are denoted with a D, and constraints that are denoted with a C. In general, problems we try to represent them as states, we move ahead to different states and try to solve those problems, in a CSP we use these 3 components, V, D, and C. V is the set of variables, this is a finite set, for example, we might have variables like V1, V2, all the way till Vn. D is the set of domains; these are also finite and there is one domain for each variable. An example of a set of domains can be D1, D2, all the way till Dn. The domain of a variable is all set of values that the variable can take, this can be a real number, imaginary number, a color, or anything. C is the set of constraints that specify the allowable combination of values. C is represented as Ci which is a tuple of two elements, scope, and relation. Ci = (scope, relation). The scope is the variables we are currently dealing with, and the relationship defines the relationship between the variables in the scope. For this example, let us assume the score is binary, which means the scope contains two variables, let\u2019s say V1 and V2. Now the relationship can be any relationship between these two variables in the scope, let\u2019s say V1 cannot be equal to V2. This relationship is our constraints applied to these two values, so in this example, V1 and V2 can take values from their domain where they do not equal each other, if the domain is a set of all integers from and including 1 to 3, then one valid case could be that V1=1 and V2=2, and an invalid case could be that V1=1 and V2=1. In a constraints satisfaction problem, we have multiple such relationships between many combinations of variables. A CSP is considered solved when all variables have a value assigned to them from the domain with no conflicts of constraints. An example of a CSP is sudoku. In sudoku we have a grid of 9x9, thus we have 81 different variables, we have some pre-filled values, for example, if we have sudoku with 11 filled values, then the set of variables contains 70 elements for each infilled box, the set of domain will be all values each box can take, which is a set consisting of the numbers 1,2,3,4,5,6,7,8,9. Finally, the constraint is that no element can be rotated in its row and column. Using a CSP algorithm like the Arc Consistency algorithm #3 or AC3, we can solve this problem. Another example of a CSP is the fa Australia map coloring problem, where we have to color the 7 regions of Australia, thus the variables are the set of all 7 regions, we can only choose from 3 colors, red, green, and blue, thus the set of the domain contains these 3 colors. Finally, the constraint is that no two neighboring regions can have the same color.","title":"Part 2"},{"location":"Question_4/","text":"4. PART 1 The SSH protocol, key generation, configuration of user settings PART 2 The principles of control, feedback control and open loop control. Set point control and reference signal tracking, the role of negative feedback. Requirements for control systems. Part 1 SSH protocol or the secure shell protocol is a method for secure remote login from one computer to another. It has a strong authentication system, it maintains the integrity of the data being sent by running on top of the TCP protocol and always listens to the TCP/IP port number 22 by default, and it is secure since it encrypts the data using encryption algorithms like Advanced Encryption Standard AES or Data Encryption Standard DES. It is more secure than other remote login protocols like telnet and it is better at exchanging data than insecure file sharing protocols like File Transfer Protocol FTP. SSH can be used via the command line to connect and issue commands to the remote computer. SSH first establishes a connection between the client and the server in three steps: Verification of server \u2013 The client initiates an SSH connection with the server, the client will authenticate the public key of the server. Generation of a session key \u2013 Once the server is verified, both client and server will negotiate a session key using a Diffie-Hellman algorithm. The generated key is a shared symmetric key that will be used for the encryption and decryption of the data. Authentication of the client \u2013 The client will send an ID for the public-private key pair. The server will check its authorized_keys file and see if the client's ID exists here. If it is found then the server will generate a random number and encrypt it using the public key, this message is sent to the client. If the client has the correct private key, it can decrypt the message and get the random number. This random number is used with the shared session key to create an MD5 hash. This MD5 hash is sent to the server, the server can use the shared session key and the original random number to calculate its MD5 hash. If the MD5 hash generated by the client matches the one generated by the server, the client has been authenticated and then the connection is completed. Instead of MD5, we can also use SHA-2 or secure hash algorithm 2. SSH is used widely for things like managing routers, server hardware, virtualization platform, remote operating systems, etc. Key generation is the process of generating keys in cryptography. A key is used to encrypt and decrypt whatever data is being encrypted/decrypted. A device or program used to generate keys is called a key generator or keygen. Modern cryptographic systems include symmetric key algorithms like Data Encryption Standard or DES and Advanced Encryption Standard or AES and public key algorithms like RSA. Symmetric key algorithms use a single shared key; keeping data secret requires keeping this key secret. Public key algorithms use a public key and a private key. The public key is made available to anyone by the means of a digital certificate. A sender encrypts the data with the receiver\u2019s public key and only the holder of this private key can then decrypt the data. The SSH protocol uses a combination of the two key algorithms since public key algorithms tend to be much slower than the symmetric key algorithm. One party receives the other\u2019s public key and encrypts a small piece of data, then the remainder of the connection uses a typically faster symmetric key algorithm for encryption. On a Linux machine, we can simply use the ssh-keygen command to generate a public/private authentication key pair. Authentication keys allow a user to connect to a remote system without supplying a password. Keys must be generated for each user separately. Use the -t option to specify the type of keys like RSA or DSA. The user can also specify a passphrase to encrypt the private key. The shh-key command will generate two keys in the hidden directory .ssh in the home directory of the user. These two files are id_rsa and id_rsa.pub. the id_rsa.pub is the public key, this should be placed in the remote systems authorized_keys directory in its .ssh hidden folder on its home directory, this directory must also have root permissions granted. Now whoever has the corresponding private key can login to this remote computer using ssh protocol. A user is an entity in Linux that can manipulate files and perform other operations. Each user is assigned a unique ID called the UID or user identifier. When the system is created ID 0 is assigned to the root user and IDs 1 to 999 are assigned to the system users and thus the IDs of local users begin from 1000. On Linux systems, user settings configuration can be done using the command line. A new user can be added using the adduser command followed by a name that has not already been taken. This command will create a new account with a new UID, the user\u2019s information is stored in the /etc/passwd and /etc/shadow files, and create a home directory for this user. The user can set a password for this account using the passwd followed by the name. A user account can be removed using the deluser command. The user configuration file which is the /etc/passwd file can be accessed using a text editor like nano since the data is stored in plaintext. The usermod command with various arguments can be used to make changes like changing the ID of the user, modifying the group ID of the user, changing the user login name, and changing the home directory of the user. The root user has access to all files on the system whereas the normal users have limited access. Part 2 Control systems manage commands, direct, or regulates the behavior of other devices or systems using control loops. A control loop is the fundamental building block of industrial control systems. Control loops are systems applied by design engineers to maintain process variables PVs at the desired value or setpoint SP. Control loops are important for maintaining the stability of a system and for consistently producing the desired outcome of a process. A basic example of a control loop is a temperature control loop. These work to maintain the temperatures in our homes and offices. The steps are as follows: The process to be controlled is established. In the case of the temperature control loop, this refers to the temperature of a substance that is being heated. Sensors measure the process value PV. In the case of the temperature control loop, the current value of the temperature, the sensor is usually a thermostat in this example. Sensors feed the measured value of the process value to the controller. In this example the temperature controller. This initiates the control process to achieve the set point or desired temperature in this example. The final control element receives the manipulated values from the controller. In this example, the temperature is increased or decreased. The core components of a control loop are: Sensors and transducers \u2013 Sensors are the initial measurement devices in a control loop. They convert the process variable PV into corresponding analog or digital signals which are read by the controllers. Transducers are advanced sensors that further transform the given values through signal conditioning. Controllers \u2013 The controller is the device that interprets the measurements fed by the sensor and determines the control action to take based on a comparison of that to the setpoint SP. PID or proportional integral derivative controllers are the most effective and stable controllers. Final control elements and actuators \u2013 Final control elements are those that receive the control action signals from the controllers. They adjust the process variable PV at the desired parameter. Actuators are an important component within final control elements. These have a direct influence on the control process. There are two types of control loops, open-loop control, and closed-loop or feedback control loops. An open-loop control system acts completely based on input; the output does not affect the control action. A closed-loop control system looks at the current output and alters it to the desired condition; also known as a feedback system, the control action in these systems is based on the output. Open-loop control is used when low cost is a priority as open control is inexpensive. They are also great when the output rarely changes if at all for example in cooling pumps. They can be used when there is no possibility of quantitative measurement or when the process is erratic, for example, a process with an erratic sensor. Closed-loop or feedback control loops are used when the measurement is feasible, and the process has a degree of predictability; that is when we have a known estimated response to the input control. We also use closed-loop control when the output varies from the desired outcome. Before working with closed-loop control, all parts must be in proper working condition and order and there must be no erratic sensors. This makes closed-loop controls more expensive than open-loop control. Setpoint in control systems is the target value that an automatic control system, for example, a PID controller will aim to reach. For example, a boiler control system will have a temperature setpoint which is set using a thermostat. This is the temperature the control system aims to attain, and the entire system will modulate the actuators to achieve it. The reference signal is the signal which is external to the control loop, this serves as the reference or the comparison to the controller variable. Reference signal tracking involves keeping track of this value and constantly updating the system to match it. Feedback loops come in two different kinds: positive and negative. Negative feedback loops are more common and work to keep a system stabilized or at equilibrium. In negative feedback, the effective input is the difference between the reference input and the feedback signal but in positive feedback, the effective input is a summation of the reference input and the feedback signal. This is why the stability of a system increases in negative feedback, but it decreases in positive feedback. Thus, the accuracy of a system also increases in negative feedback. An electronic amplifier is an example of a negative feedback system. We prefer negative feedback to positive feedback since positive feedback tends to lead to instability due to exponential growth or chaotic behavior, on the other hand, negative feedback promotes stability. Requirements of a good control system: Sensitivity \u2013 The rate of change of a control system with the change in its surroundings is called sensitivity. A good control system should be sensitive to its input only and should not be sensitive to the surrounding parameters. Accuracy \u2013 The tolerance of errors of an instrument is known as accuracy. We can improve the accuracy by using feedback elements like adding an error detector circuit in the control system to increase the accuracy. Stability \u2013 If the input of a system is zero then the output should also be a zero value. If the input changes, the output also changes as per the system function, this is a stable system. Noise \u2013 Undesired signal input due to external sources is known as noise. A good control system should have a high noise tolerance value, so it can reduce the noise level. System performance decreases as noise value increases. Speed \u2013 In control systems, the time taken by the output to be stable is known as speed. High-speed systems are considered good control systems. Bandwidth \u2013 Bandwidth is the range of frequencies of a system. Bandwidth is decided by the operating frequencies. A system having a high bandwidth is considered a good control system. Oscillation \u2013 Oscillation means the fluctuations of the output of a system. These oscillations affect the stability and a higher number of these fluctuations in a system will decrease the stability of a system.","title":"Question 4"},{"location":"Question_4/#4-part-1-the-ssh-protocol-key-generation-configuration-of-user-settings-part-2-the-principles-of-control-feedback-control-and-open-loop-control-set-point-control-and-reference-signal-tracking-the-role-of-negative-feedback-requirements-for-control-systems","text":"","title":"4. PART 1 The SSH protocol, key generation, configuration of user settings PART 2 The principles of control, feedback control and open loop control. Set point control and reference signal tracking, the role of negative feedback. Requirements for control systems."},{"location":"Question_4/#part-1","text":"SSH protocol or the secure shell protocol is a method for secure remote login from one computer to another. It has a strong authentication system, it maintains the integrity of the data being sent by running on top of the TCP protocol and always listens to the TCP/IP port number 22 by default, and it is secure since it encrypts the data using encryption algorithms like Advanced Encryption Standard AES or Data Encryption Standard DES. It is more secure than other remote login protocols like telnet and it is better at exchanging data than insecure file sharing protocols like File Transfer Protocol FTP. SSH can be used via the command line to connect and issue commands to the remote computer. SSH first establishes a connection between the client and the server in three steps: Verification of server \u2013 The client initiates an SSH connection with the server, the client will authenticate the public key of the server. Generation of a session key \u2013 Once the server is verified, both client and server will negotiate a session key using a Diffie-Hellman algorithm. The generated key is a shared symmetric key that will be used for the encryption and decryption of the data. Authentication of the client \u2013 The client will send an ID for the public-private key pair. The server will check its authorized_keys file and see if the client's ID exists here. If it is found then the server will generate a random number and encrypt it using the public key, this message is sent to the client. If the client has the correct private key, it can decrypt the message and get the random number. This random number is used with the shared session key to create an MD5 hash. This MD5 hash is sent to the server, the server can use the shared session key and the original random number to calculate its MD5 hash. If the MD5 hash generated by the client matches the one generated by the server, the client has been authenticated and then the connection is completed. Instead of MD5, we can also use SHA-2 or secure hash algorithm 2. SSH is used widely for things like managing routers, server hardware, virtualization platform, remote operating systems, etc. Key generation is the process of generating keys in cryptography. A key is used to encrypt and decrypt whatever data is being encrypted/decrypted. A device or program used to generate keys is called a key generator or keygen. Modern cryptographic systems include symmetric key algorithms like Data Encryption Standard or DES and Advanced Encryption Standard or AES and public key algorithms like RSA. Symmetric key algorithms use a single shared key; keeping data secret requires keeping this key secret. Public key algorithms use a public key and a private key. The public key is made available to anyone by the means of a digital certificate. A sender encrypts the data with the receiver\u2019s public key and only the holder of this private key can then decrypt the data. The SSH protocol uses a combination of the two key algorithms since public key algorithms tend to be much slower than the symmetric key algorithm. One party receives the other\u2019s public key and encrypts a small piece of data, then the remainder of the connection uses a typically faster symmetric key algorithm for encryption. On a Linux machine, we can simply use the ssh-keygen command to generate a public/private authentication key pair. Authentication keys allow a user to connect to a remote system without supplying a password. Keys must be generated for each user separately. Use the -t option to specify the type of keys like RSA or DSA. The user can also specify a passphrase to encrypt the private key. The shh-key command will generate two keys in the hidden directory .ssh in the home directory of the user. These two files are id_rsa and id_rsa.pub. the id_rsa.pub is the public key, this should be placed in the remote systems authorized_keys directory in its .ssh hidden folder on its home directory, this directory must also have root permissions granted. Now whoever has the corresponding private key can login to this remote computer using ssh protocol. A user is an entity in Linux that can manipulate files and perform other operations. Each user is assigned a unique ID called the UID or user identifier. When the system is created ID 0 is assigned to the root user and IDs 1 to 999 are assigned to the system users and thus the IDs of local users begin from 1000. On Linux systems, user settings configuration can be done using the command line. A new user can be added using the adduser command followed by a name that has not already been taken. This command will create a new account with a new UID, the user\u2019s information is stored in the /etc/passwd and /etc/shadow files, and create a home directory for this user. The user can set a password for this account using the passwd followed by the name. A user account can be removed using the deluser command. The user configuration file which is the /etc/passwd file can be accessed using a text editor like nano since the data is stored in plaintext. The usermod command with various arguments can be used to make changes like changing the ID of the user, modifying the group ID of the user, changing the user login name, and changing the home directory of the user. The root user has access to all files on the system whereas the normal users have limited access.","title":"Part 1"},{"location":"Question_4/#part-2","text":"Control systems manage commands, direct, or regulates the behavior of other devices or systems using control loops. A control loop is the fundamental building block of industrial control systems. Control loops are systems applied by design engineers to maintain process variables PVs at the desired value or setpoint SP. Control loops are important for maintaining the stability of a system and for consistently producing the desired outcome of a process. A basic example of a control loop is a temperature control loop. These work to maintain the temperatures in our homes and offices. The steps are as follows: The process to be controlled is established. In the case of the temperature control loop, this refers to the temperature of a substance that is being heated. Sensors measure the process value PV. In the case of the temperature control loop, the current value of the temperature, the sensor is usually a thermostat in this example. Sensors feed the measured value of the process value to the controller. In this example the temperature controller. This initiates the control process to achieve the set point or desired temperature in this example. The final control element receives the manipulated values from the controller. In this example, the temperature is increased or decreased. The core components of a control loop are: Sensors and transducers \u2013 Sensors are the initial measurement devices in a control loop. They convert the process variable PV into corresponding analog or digital signals which are read by the controllers. Transducers are advanced sensors that further transform the given values through signal conditioning. Controllers \u2013 The controller is the device that interprets the measurements fed by the sensor and determines the control action to take based on a comparison of that to the setpoint SP. PID or proportional integral derivative controllers are the most effective and stable controllers. Final control elements and actuators \u2013 Final control elements are those that receive the control action signals from the controllers. They adjust the process variable PV at the desired parameter. Actuators are an important component within final control elements. These have a direct influence on the control process. There are two types of control loops, open-loop control, and closed-loop or feedback control loops. An open-loop control system acts completely based on input; the output does not affect the control action. A closed-loop control system looks at the current output and alters it to the desired condition; also known as a feedback system, the control action in these systems is based on the output. Open-loop control is used when low cost is a priority as open control is inexpensive. They are also great when the output rarely changes if at all for example in cooling pumps. They can be used when there is no possibility of quantitative measurement or when the process is erratic, for example, a process with an erratic sensor. Closed-loop or feedback control loops are used when the measurement is feasible, and the process has a degree of predictability; that is when we have a known estimated response to the input control. We also use closed-loop control when the output varies from the desired outcome. Before working with closed-loop control, all parts must be in proper working condition and order and there must be no erratic sensors. This makes closed-loop controls more expensive than open-loop control. Setpoint in control systems is the target value that an automatic control system, for example, a PID controller will aim to reach. For example, a boiler control system will have a temperature setpoint which is set using a thermostat. This is the temperature the control system aims to attain, and the entire system will modulate the actuators to achieve it. The reference signal is the signal which is external to the control loop, this serves as the reference or the comparison to the controller variable. Reference signal tracking involves keeping track of this value and constantly updating the system to match it. Feedback loops come in two different kinds: positive and negative. Negative feedback loops are more common and work to keep a system stabilized or at equilibrium. In negative feedback, the effective input is the difference between the reference input and the feedback signal but in positive feedback, the effective input is a summation of the reference input and the feedback signal. This is why the stability of a system increases in negative feedback, but it decreases in positive feedback. Thus, the accuracy of a system also increases in negative feedback. An electronic amplifier is an example of a negative feedback system. We prefer negative feedback to positive feedback since positive feedback tends to lead to instability due to exponential growth or chaotic behavior, on the other hand, negative feedback promotes stability. Requirements of a good control system: Sensitivity \u2013 The rate of change of a control system with the change in its surroundings is called sensitivity. A good control system should be sensitive to its input only and should not be sensitive to the surrounding parameters. Accuracy \u2013 The tolerance of errors of an instrument is known as accuracy. We can improve the accuracy by using feedback elements like adding an error detector circuit in the control system to increase the accuracy. Stability \u2013 If the input of a system is zero then the output should also be a zero value. If the input changes, the output also changes as per the system function, this is a stable system. Noise \u2013 Undesired signal input due to external sources is known as noise. A good control system should have a high noise tolerance value, so it can reduce the noise level. System performance decreases as noise value increases. Speed \u2013 In control systems, the time taken by the output to be stable is known as speed. High-speed systems are considered good control systems. Bandwidth \u2013 Bandwidth is the range of frequencies of a system. Bandwidth is decided by the operating frequencies. A system having a high bandwidth is considered a good control system. Oscillation \u2013 Oscillation means the fluctuations of the output of a system. These oscillations affect the stability and a higher number of these fluctuations in a system will decrease the stability of a system.","title":"Part 2"},{"location":"Question_5/","text":"5. PART 1 Present the adversarial searches and the conditions necessary for the existence of a winning strategy. PART 2 MOS transistor: large signal model and characteristics. The MOS transistor as a switch. CMOS inverter, basic logic gates. The operational amplifier. Negative feedback. Basic applications. Part 1 Adversarial search is a search where we examine a problem that arises when we try to plan, and other agents are planning against us. This type of search strategy is not associated with a single agent, instead, there is more than one agent which is searching for the solution in the same search space. This situation usually occurs in game playing. An environment with more than one agent is called a multi-agent environment, in this, each agent is an opponent of the other agent and playing against each other. Each agent has to consider the action of other agents and the effect of that action on their performance. Games are modeled as a search problem and heuristic evaluation function; these are the two main factors that help to model and solve games in artificial intelligence. The types of games in AI: Perfect information \u2013 In this type of game, the agents have all the information or in other words can see the entire game board. They can see their opponent agent\u2019s moves and current positions. Examples are chess and checkers. Imperfect information \u2013 In this type of game the agents do not have all the information about the game, they might have partial information, but never the entire information. Examples are tic tac toe and battleship. Deterministic Games \u2013 These types of games follow a strict pattern and set of rules for the games. There is no randomness associated with them. Examples are chess and tic tac toe. Non-deterministic games \u2013 These types of games have various unpredictable events and have a factor of chance or luck. This luck factor is introduced by dice or cards. Examples are monopoly and poker. Zero-Sum games are adversarial search that involves pure competition. In these games, each agent\u2019s gain or loss is perfectly balanced by the losses and gains of the competing agent. One player of the game tries to maximize one single value, while the other player tries to minimize it. A problem can be formalized with the following elements: Initial state \u2013 This specifies how the game is set up at the start. Players \u2013 This specifies which player has moved in the state space Actions \u2013 This returns the set of legal moves in the state space Results \u2013 This is the transition model, which specifies the result of moves in the state space. Terminal-test \u2013 This is set to true if the game is over, else this is false in all other cases. The state where the game ends is called the terminal state. Utility function \u2013 This gives a numeric value for the terminal states. This can be won, lose, drawn, or any numerical value. The Minimax algorithm is a very famous example of an adversarial search algorithm used to solve two player games in which we are competing against one opponent agent. Usually, both agents taking part in such games have complete information, thus they are perfect information games. Minimax algorithm is a backtracking algorithm, which means we begin at the root node and traverse deep to the terminal nodes, here we calculate the values and propagate back to the root node and then choose the value or path to take. In such games, we deal with the concept of the best move or optimal move. Here both competing agents will make moves that are optimal towards making them the winner, this results in the optimal moves for each side being the worst-case scenario for the opponent agent. The reason this algorithm is called the Minimax algorithm is since we are dealing with two agents, the first one is MAX and the second one is MIN. In a Minimax algorithm, we form a binary game tree, each node will have 2 child nodes and this tree will increase based on the complexity, usually, the root node is where the MAX agent will have its chance, on the next level will be MIN agent and this way we keep on alternating one by one. The objective of MAX is to maximize its utility, and MIN will try to minimize its utility. MAX will try to make the best move from the point of view of the MAX agent, while MIN will try to make the worst movie from the point of view of the MAX agent, which in turn will be the best move from its point of view. We start with MAX at the root node, we can take one of two paths, once the path is chosen, now is the turn for MIN, it will have two paths as well. The leaf nodes or the terminal nodes have utility values, the negative values indicate that the MIN agent has won, and the positive values indicate that the MAX agent has won. Using backtracking and keeping in mind the chance of either MIN or MAX agent, we can determine the utility value for each node. The time complexity of this algorithm is O(bd) where b is the branching factor, or the number of possible choices and d is the depth. This is fine for games with a smaller number of choices, but the time complexity goes exponentially up for games like chess where there are lots of choices, this level of the game tree is not feasible. To improve on the Minimax algorithm, we can use Alpha-beta pruning. Alpha-beta pruning can reduce the time complexity of the Minimax algorithm by cutting off or pruning some nodes, thus we do not traverse every single branch to find the optimal route for the MAX agent. This is done by pruning off the parts when we already found a better path. To find a path to prune, if a certain path\u2019s parent node or any other node further up is a better choice, then we do not need to traverse that path at all. To calculate this we use two values, alpha, and beta. Alpha is the best choice or highest value we have found so far at any point along the path for MATH, alpha acts as a lower bound for all MAX nodes, thus only MAX nodes update the value of alpha. Initially, we take the value of alpha to be negative infinity. Beta is the best choice or lowest value we have found so far at any point along the path for MIN, it acts as an upper bound for all MIN values, thus only MIN nodes update the value of beta. Initially, we take the value of beta to be positive infinity. Since MINIMAX follows a depth-first search, we will start at the deepest left side node of the tree with values for alpha being negative infinity and beta being positive infinity. Using the same strategy as MINIMAX, we will find the values of alpha and beta, and using the construct that at a MAX node, the value must be equal to or greater than alpha, and at a MIN node, the value must be less than or equal to the beta, we will find the node values. But this way when we start to traverse a new node, we will first see if it follows the alpha-beta construct, if it does not then we can prune that branch since there is no point in visiting that branch. Alpha-beta pruning gives us the same steps as MINIMAX's final answer but uses less time to do so. Part 2 A MOS transistor is also called a MOSFET transistor is the metal oxide semiconductor field-effect transistor. This transistor has four terminals, gate, substrate, drain, and source. The device is formed using the MOS structure in which we have three layers stacked on top of each other, the top layer is the metal layer, the second layer is the silicon oxide layer, and the last layer is the substrate layer. The top metal layer is connected to the gate terminal and has a gate voltage. The substrate layer is connected to the substrate terminal and has a substrate voltage. Concerning channel, we have two types of MOS transistors: Enhancement type \u2013 this has no conducting channel region between the source and drain when the gate voltage is zero. Depletion type \u2013 this has a conducting channel region between the source and drain when a gate bias voltage is 0. MOSFETS vary the voltage on the gate by changing the resistance on the source and drain terminals. An example is an NMOS transistor in which we have a P-type substrate on which we create two heavily doped n-type regions, one of them is the source and the other is the drain. The oxide layer is deposited on top of the source and drain and then comes the metal layer on top of that. When a positive voltage is applied to the gate, this causes the depletion region to connect both the source and drain causing a field effect. At this point the electricity is not flowing, before the gate voltage has reached the threshold voltage, this is called saturation. When the gate voltage surpasses the threshold voltage the current flows between the source and drain. A large-signal model is an analysis method for transistors where we have nonlinear elements. Under large-signal conditions, AC signals have a high enough magnitude that nonlinear effects must be considered. In a large signal model, the large signal affects the operating point. The non-linear elements can be limited by power supply values to avoid variation in operating points. A small-signal model ignores these variations. MOS transistors can be used as a switch to turn on and off. Billions of these switches are used in modern microprocessors. MOS transistors are good for switching since they are good for high power applications since they can switch faster, this lets them use smaller inductors and supplies, this, in turn, increases the efficiency of MOS transistors as a switch. When the gate voltage of the MOS transistor is less than the threshold voltage, the circuit is considered open and has no current flow, this is the OFF state. When the gate voltage of the MOS transistor is more than the threshold voltage, the circuit is closed, the current value is more than 0, this is the ON state. CMOS inverter or simply CMOS is a complementary metal-oxide semiconductor that acts as a NOT gate or an inverter. A high voltage or a logic 1 will result in a logic 0 output and a low voltage or a logic 0 will result in a logic 1 output. A CMOS inverter is created with one PMOS or P-type channel MOS and one NMOS or N-type channel MOS. A PMOS has a P-type source and drain on an N-type substrate, and we have the output connected near the ground. PMOS gives a low output for high input and high output for low input. An NMOS has an N-type source and drains on a P-type substrate, and we have the output connected near the gate voltage. NMOS also gives a low output for high input and high output for low input, thus both PMOS and NMOS act as inverters. To create a CMOS inverter, we connect the PMOS and NMOS outputs with PMOS connected to the gate voltage and the NMOS connected to the ground. When the input is a logic 0, the NMOS circuit is open and the PMOS circuit is shorted, which means the PMOS is active, and we get a logic 1. When the input logic is 1, the PMOS circuit is open and the NMOS circuit is shorted, here the output connects to the ground and thus we get a logic 0. We use a CMOS inverter since it consumes less power when switching at high frequencies. We can create a CMOS NAND gate using two PMOS and two NMOS. We connect the two PMOS in parallel and the two NMOS in series. The output is joined for all, the PMOS circuit connects to the gate voltage and the NMOS circuit connects to the ground. We have two inputs A and B. A is given to one PMOS and one NMOS and B is also given to one PMOS and one NMOS. In this circuit, when we apply logic 1 on both A and B, we get a logic 0 as output, and we get logic 1 in any other case. We can also create an AND gate by connecting the output of the CMOS NAND gate to a CMOS inverter. We can create a CMOS NOR gate using two PMOS and two NMOS. We connect the two PMOS in series and the two NMOS in parallel. The output is joined for all, the PMOS circuit connects to the gate voltage and the NMOS circuit connects to the ground. We have two inputs A and B. A is given to one PMOS and one NMOS and B is also given to one PMOS and one NMOS. In this circuit, when we apply a logic 0 on both A and B, then we get a logic 1 as output, and we get a logic 0 in any other case. We can also create an OR gate by connecting the output of the CMOS NOR gate to a CMOS inverter. The operational amplifier is a type of amplifier, amplifiers are devices that take in a signal and produce the same signal with a larger amplitude. Op-amps have a positive input called the non-inverting input and a negative input called the inverting input, the difference between these two inputs is the final input, thus this is called differential input. The output is the product of the differential inputs and the high gain of this device. Op-amps have a very high gain like 105 which makes the circuit design difficult because of high gain sensitivity. Negative feedback is when we connect the output back to the inverting input, this makes it possible to set again and cut off frequency to the desired value, which improves the stability and reduced variation. Op-amps are used for AC and DC signal amplification, voltage regulators, and as filters.","title":"Question 5"},{"location":"Question_5/#5-part-1-present-the-adversarial-searches-and-the-conditions-necessary-for-the-existence-of-a-winning-strategy-part-2-mos-transistor-large-signal-model-and-characteristics-the-mos-transistor-as-a-switch-cmos-inverter-basic-logic-gates-the-operational-amplifier-negative-feedback-basic-applications","text":"","title":"5. PART 1 Present the adversarial searches and the conditions necessary for the existence of a winning strategy. PART 2 MOS transistor: large signal model and characteristics. The MOS transistor as a switch. CMOS inverter, basic logic gates. The operational amplifier. Negative feedback. Basic applications."},{"location":"Question_5/#part-1","text":"Adversarial search is a search where we examine a problem that arises when we try to plan, and other agents are planning against us. This type of search strategy is not associated with a single agent, instead, there is more than one agent which is searching for the solution in the same search space. This situation usually occurs in game playing. An environment with more than one agent is called a multi-agent environment, in this, each agent is an opponent of the other agent and playing against each other. Each agent has to consider the action of other agents and the effect of that action on their performance. Games are modeled as a search problem and heuristic evaluation function; these are the two main factors that help to model and solve games in artificial intelligence. The types of games in AI: Perfect information \u2013 In this type of game, the agents have all the information or in other words can see the entire game board. They can see their opponent agent\u2019s moves and current positions. Examples are chess and checkers. Imperfect information \u2013 In this type of game the agents do not have all the information about the game, they might have partial information, but never the entire information. Examples are tic tac toe and battleship. Deterministic Games \u2013 These types of games follow a strict pattern and set of rules for the games. There is no randomness associated with them. Examples are chess and tic tac toe. Non-deterministic games \u2013 These types of games have various unpredictable events and have a factor of chance or luck. This luck factor is introduced by dice or cards. Examples are monopoly and poker. Zero-Sum games are adversarial search that involves pure competition. In these games, each agent\u2019s gain or loss is perfectly balanced by the losses and gains of the competing agent. One player of the game tries to maximize one single value, while the other player tries to minimize it. A problem can be formalized with the following elements: Initial state \u2013 This specifies how the game is set up at the start. Players \u2013 This specifies which player has moved in the state space Actions \u2013 This returns the set of legal moves in the state space Results \u2013 This is the transition model, which specifies the result of moves in the state space. Terminal-test \u2013 This is set to true if the game is over, else this is false in all other cases. The state where the game ends is called the terminal state. Utility function \u2013 This gives a numeric value for the terminal states. This can be won, lose, drawn, or any numerical value. The Minimax algorithm is a very famous example of an adversarial search algorithm used to solve two player games in which we are competing against one opponent agent. Usually, both agents taking part in such games have complete information, thus they are perfect information games. Minimax algorithm is a backtracking algorithm, which means we begin at the root node and traverse deep to the terminal nodes, here we calculate the values and propagate back to the root node and then choose the value or path to take. In such games, we deal with the concept of the best move or optimal move. Here both competing agents will make moves that are optimal towards making them the winner, this results in the optimal moves for each side being the worst-case scenario for the opponent agent. The reason this algorithm is called the Minimax algorithm is since we are dealing with two agents, the first one is MAX and the second one is MIN. In a Minimax algorithm, we form a binary game tree, each node will have 2 child nodes and this tree will increase based on the complexity, usually, the root node is where the MAX agent will have its chance, on the next level will be MIN agent and this way we keep on alternating one by one. The objective of MAX is to maximize its utility, and MIN will try to minimize its utility. MAX will try to make the best move from the point of view of the MAX agent, while MIN will try to make the worst movie from the point of view of the MAX agent, which in turn will be the best move from its point of view. We start with MAX at the root node, we can take one of two paths, once the path is chosen, now is the turn for MIN, it will have two paths as well. The leaf nodes or the terminal nodes have utility values, the negative values indicate that the MIN agent has won, and the positive values indicate that the MAX agent has won. Using backtracking and keeping in mind the chance of either MIN or MAX agent, we can determine the utility value for each node. The time complexity of this algorithm is O(bd) where b is the branching factor, or the number of possible choices and d is the depth. This is fine for games with a smaller number of choices, but the time complexity goes exponentially up for games like chess where there are lots of choices, this level of the game tree is not feasible. To improve on the Minimax algorithm, we can use Alpha-beta pruning. Alpha-beta pruning can reduce the time complexity of the Minimax algorithm by cutting off or pruning some nodes, thus we do not traverse every single branch to find the optimal route for the MAX agent. This is done by pruning off the parts when we already found a better path. To find a path to prune, if a certain path\u2019s parent node or any other node further up is a better choice, then we do not need to traverse that path at all. To calculate this we use two values, alpha, and beta. Alpha is the best choice or highest value we have found so far at any point along the path for MATH, alpha acts as a lower bound for all MAX nodes, thus only MAX nodes update the value of alpha. Initially, we take the value of alpha to be negative infinity. Beta is the best choice or lowest value we have found so far at any point along the path for MIN, it acts as an upper bound for all MIN values, thus only MIN nodes update the value of beta. Initially, we take the value of beta to be positive infinity. Since MINIMAX follows a depth-first search, we will start at the deepest left side node of the tree with values for alpha being negative infinity and beta being positive infinity. Using the same strategy as MINIMAX, we will find the values of alpha and beta, and using the construct that at a MAX node, the value must be equal to or greater than alpha, and at a MIN node, the value must be less than or equal to the beta, we will find the node values. But this way when we start to traverse a new node, we will first see if it follows the alpha-beta construct, if it does not then we can prune that branch since there is no point in visiting that branch. Alpha-beta pruning gives us the same steps as MINIMAX's final answer but uses less time to do so.","title":"Part 1"},{"location":"Question_5/#part-2","text":"A MOS transistor is also called a MOSFET transistor is the metal oxide semiconductor field-effect transistor. This transistor has four terminals, gate, substrate, drain, and source. The device is formed using the MOS structure in which we have three layers stacked on top of each other, the top layer is the metal layer, the second layer is the silicon oxide layer, and the last layer is the substrate layer. The top metal layer is connected to the gate terminal and has a gate voltage. The substrate layer is connected to the substrate terminal and has a substrate voltage. Concerning channel, we have two types of MOS transistors: Enhancement type \u2013 this has no conducting channel region between the source and drain when the gate voltage is zero. Depletion type \u2013 this has a conducting channel region between the source and drain when a gate bias voltage is 0. MOSFETS vary the voltage on the gate by changing the resistance on the source and drain terminals. An example is an NMOS transistor in which we have a P-type substrate on which we create two heavily doped n-type regions, one of them is the source and the other is the drain. The oxide layer is deposited on top of the source and drain and then comes the metal layer on top of that. When a positive voltage is applied to the gate, this causes the depletion region to connect both the source and drain causing a field effect. At this point the electricity is not flowing, before the gate voltage has reached the threshold voltage, this is called saturation. When the gate voltage surpasses the threshold voltage the current flows between the source and drain. A large-signal model is an analysis method for transistors where we have nonlinear elements. Under large-signal conditions, AC signals have a high enough magnitude that nonlinear effects must be considered. In a large signal model, the large signal affects the operating point. The non-linear elements can be limited by power supply values to avoid variation in operating points. A small-signal model ignores these variations. MOS transistors can be used as a switch to turn on and off. Billions of these switches are used in modern microprocessors. MOS transistors are good for switching since they are good for high power applications since they can switch faster, this lets them use smaller inductors and supplies, this, in turn, increases the efficiency of MOS transistors as a switch. When the gate voltage of the MOS transistor is less than the threshold voltage, the circuit is considered open and has no current flow, this is the OFF state. When the gate voltage of the MOS transistor is more than the threshold voltage, the circuit is closed, the current value is more than 0, this is the ON state. CMOS inverter or simply CMOS is a complementary metal-oxide semiconductor that acts as a NOT gate or an inverter. A high voltage or a logic 1 will result in a logic 0 output and a low voltage or a logic 0 will result in a logic 1 output. A CMOS inverter is created with one PMOS or P-type channel MOS and one NMOS or N-type channel MOS. A PMOS has a P-type source and drain on an N-type substrate, and we have the output connected near the ground. PMOS gives a low output for high input and high output for low input. An NMOS has an N-type source and drains on a P-type substrate, and we have the output connected near the gate voltage. NMOS also gives a low output for high input and high output for low input, thus both PMOS and NMOS act as inverters. To create a CMOS inverter, we connect the PMOS and NMOS outputs with PMOS connected to the gate voltage and the NMOS connected to the ground. When the input is a logic 0, the NMOS circuit is open and the PMOS circuit is shorted, which means the PMOS is active, and we get a logic 1. When the input logic is 1, the PMOS circuit is open and the NMOS circuit is shorted, here the output connects to the ground and thus we get a logic 0. We use a CMOS inverter since it consumes less power when switching at high frequencies. We can create a CMOS NAND gate using two PMOS and two NMOS. We connect the two PMOS in parallel and the two NMOS in series. The output is joined for all, the PMOS circuit connects to the gate voltage and the NMOS circuit connects to the ground. We have two inputs A and B. A is given to one PMOS and one NMOS and B is also given to one PMOS and one NMOS. In this circuit, when we apply logic 1 on both A and B, we get a logic 0 as output, and we get logic 1 in any other case. We can also create an AND gate by connecting the output of the CMOS NAND gate to a CMOS inverter. We can create a CMOS NOR gate using two PMOS and two NMOS. We connect the two PMOS in series and the two NMOS in parallel. The output is joined for all, the PMOS circuit connects to the gate voltage and the NMOS circuit connects to the ground. We have two inputs A and B. A is given to one PMOS and one NMOS and B is also given to one PMOS and one NMOS. In this circuit, when we apply a logic 0 on both A and B, then we get a logic 1 as output, and we get a logic 0 in any other case. We can also create an OR gate by connecting the output of the CMOS NOR gate to a CMOS inverter. The operational amplifier is a type of amplifier, amplifiers are devices that take in a signal and produce the same signal with a larger amplitude. Op-amps have a positive input called the non-inverting input and a negative input called the inverting input, the difference between these two inputs is the final input, thus this is called differential input. The output is the product of the differential inputs and the high gain of this device. Op-amps have a very high gain like 105 which makes the circuit design difficult because of high gain sensitivity. Negative feedback is when we connect the output back to the inverting input, this makes it possible to set again and cut off frequency to the desired value, which improves the stability and reduced variation. Op-amps are used for AC and DC signal amplification, voltage regulators, and as filters.","title":"Part 2"},{"location":"Question_6/","text":"6. PART 1 Sequential logical: Latches and Flip-Flops. Counters. Shift registers. Memories. PART 2 New elements of HTML5. New features of CSS3. Control structures in web scripts. Sensor through a web page. Providing remote management systems through a web page. Part 1 Sequential logic is a form of binary circuit design that has one or more inputs and one or more outputs, whose states are dependent in part on the previous states. Sequential logic circuits have some form of inherent memory built-in. Sequential logic circuits remember the conditions and stay fixed in their current state until the next clock signal changes one of the states. Latches are basic storage elements that operate with signal levels. Latches are level-sensitive devices and are useful for the design of asynchronous sequential circuits. There are two basic latches called the SR latch and the D latch. SR latch is a circuit with two cross-coupled NOR gates or two cross-coupled NAND gates with two inputs labeled S for set and R for a reset with two outputs Q and Q prime. This latch has two useful states. When the output Q is 1 and Q prime is 0, the latch is said to be inset state. When Q is 0 and Q prime is 1, then it is in a reset state. Normally the outputs Q and Q prime complement each other. An SR Nor latch has these states: When S is 0 and R is 1, then the output Q is 0 and Q prime is 1. This is the reset condition. Now if R goes back to 0, the reset state remains, now S and R are 0 but the previous output has been stored as memory. When S is 1 and R is 0, then Q prime is 0 and Q is 1. This is the set state. Now if S goes back to 0, the circuit remains in the set state. When S and R are both 1, then Q and Q prime become 0, this violates that both outputs must complement each other, this condition is avoided by making sure that 1s are not applied to both inputs simultaneously, this is the invalid state. To fix the drawback of the invalid state where both inputs are 1, we use the D latch, which has a single input D by sending the same signal to both S and R but placing an inverter in front of either one of them. This ensures that the input to one is always the opposite of the input to the other. Flip-Flops are just edge-triggered latches, it only changes state when a control signal goes from high to low or low to high. This makes using flip-flops with clock signals possible. We have SR flip-flops and D flip-flops which are the same as the latches. We have other flip-flops like JK flip-flop and T flip-flop. Counters are devices that store the number of times a particular event or process has occurred, often in relationship to a clock. A 4-bit ripple counter will count from 0000 or 0 to 1111 or 15. This can be made by chaining 4 T flip-flops together. Each clock pulse causes a change that ripples through the chain of flip flops with a delay. We also have synchronous counters which use the same clock signal on all flip-flops, this uses more circuitry but has no delay. There are also ring counters which are composed of flip-flops connected into a shift register, with the output of the last flip-flop fed to the input of the first, making a circular or ring structure. There are two types of ring counters, a straight ring counter connects the output of the last shift register to the first shift register input, this circulates a single one or zero bit around the ring. A twisted ring counter connects the complement of the output of the last shift register to the input of the first register and circulates a stream of ones followed by zeros around the ring. Flip-flops can be used to store a single bit of binary data. To store multiple bits of data, we need multiple flip-flops, N flip-flops connected to store n bits of data are called registers. A shift register is a type of digital circuit using a cascade of flip-flops where the output of one flip-flop is connected to the input of the next. They share a single clock signal which causes the data stores in the system to shift from one location to the next. By connecting the last flip-flop back to the first, the data can cycle within the shifters for extended periods and in this form, they are used as a form of computer memory. The registers which shift the bits to the left are called shift left registers and the registers which will shift the bits to the right are called shift right registers. We have 4 basic types of shift registers: Serial in serial out \u2013 these allow serial input and produce serial output. Serial in parallel out \u2013 these allow serial input and produce a parallel output. Parallel in serial out \u2013 these allow parallel input and produce a serial output. Parallel in parallel out \u2013 these allow parallel input and produce a parallel output. System memory is like a human brain. It is used to store data and instructions. Computer memory is the storage space in computers where data to be processed and instructions required for processing are stored. The memory is divided into a large number of small parts. Each part is called a cell and each location or cell has a unique address that varies from zero to memory size minus one. Memory is primarily of two types, internal memory like cache memory and primary memory, and external memory like magnetic disk, optical disk, or flash storage. Part 2 HTML 5 introduced the following new elements: Article \u2013 represents an independent piece of content of a document, such as a block entry or newspaper article. Aside \u2013 Represents a piece of content that is only slightly related to the rest of the page. Audio \u2013 defines an audio file. Canvas \u2013 This is used for rendering dynamic bitmap graphics on the fly, such as graphs or games. Command \u2013 Represents a command the user can invoke. Datalist \u2013 Together with the new list attribute for input, can be used to make combo boxes. Details \u2013 Represents additional information or controls which the user can obtain on demand. Embed \u2013 Defines external interactive content or plugin. Figure \u2013 Represents a piece of self-contained flow content, typically referenced as a single unit from the main flow of the document. Footer \u2013 Represents a footer for a section and can contain information about the author, copyright information, etc. Header \u2013 Represents a group of introductory or navigational aids. Group \u2013 represents the header of a section. Keygen \u2013 Represents a control for key pair generation. Mark \u2013 Represents a run of text in one document marked or highlighted for reference purposes. Meter \u2013 Represents a measurement such as a disk usage. Nav \u2013 Represents a section of the document intended for navigation. Output \u2013 Represents some type of output, such as from a calculation done through scripting. Progress \u2013 Represents a completion of a task, such as downloading or when performing a series of expensive operations. Ruby \u2013 Together with rt and RP allows for marking up ruby annotations. Section \u2013 Represents a generic document or application section. Time \u2013 Represents a date or time. Video \u2013 Defines a video file. Wbr \u2013 Represents a line break opportunity. New features of CSS3 are as follows: Advanced animations \u2013 We can utilize both transition and animation when it is required to change a component starting with one state moving onto the next. With transitions, a user can make float or mouse down effects or trigger the animation by changing the style of a component with JavaScript. Multiple backgrounds and gradient \u2013 With multiple backgrounds, creators can stack various pictures as backgrounds of a component. Each picture or layer can be moved and animated with ease. CSS3 also allows for gradients as backgrounds. Multiple column layouts \u2013 This feature enables web designers to display their content in multiple sections with alternatives like column-width, column-gap, etc. Opacity \u2013 This property can make components more transparent. The opacity ranges from 0 which is transparent to 1 which is opaque. Rounded corner \u2013 This feature is very famous among social media giants. Rounded corners can make a site look tidier. Selectors \u2013 these are patterns or elements and other terms that tell the browser which HTML elements should be selected to have the CSS property values inside the rule applied to them. The elements selected by the selector are called the subject of the selector. Control structures are programming constructs that determine which statements or procedures are executed at a given point in a program, either based on the evaluation of one or more variables or in response to some external input. In the absence of control structures, program statements will execute sequentially or in the order in which they appear in the code. There are two basic kinds of control structures \u2013 conditional and iterative. A conditional control structure typically defines a sequence of one or more program statements that will be executed if a particular condition is met. An iterative control structure loops through or iterates a sequence of program statements repeatedly until some predetermined exit condition is met. Program loops can be for example a counting loop that iterates a fixed number of times and then exits the loop. The number of iterations is determined by the value of a counter variable. In web scripts we have some basic types of control structures: If-else \u2013 This evaluates a condition as a true or false value, if the value is true, the block following if statement is executed, if this is false then the block following else is executed. We can only execute one of the two blocks for a given expression. Switch \u2013 The switch statement allows us to make multiple if-else constructs more elegantly. We have a statement that might have multiple outputs, for each discrete output we have a different switch case. We also have a default case for when none of the given cases are met. For a given expression only one case can be executed at a time. For loop \u2013 This control structure has a counter variable and will run a block of code for a specified number of times, specified by the counter variable. Once this number has been reached, the program exits the loop. For in \u2013 This control structure iterates through the enumerable properties of a JavaScript object. While loop \u2013 This loop executes a block of code over and over until a certain condition is met. This condition is defined outside the loop and can be changed within the loop. Once this condition is met, the loop exits. Try catch \u2013 The try-catch block is used to handle exceptions. The code is first sent to the try block, if it doesn\u2019t throw an error, the next catch block is ignored, and program flow continues. If the try block throws an error, the control is transferred to the catch block which will execute the given exception handler. Sensor data is used by many web apps to enable immersive gaming, fitness tracking, and augmented reality applications. The Generic Sensor API is a set of interfaces that expose sensor devices to the web platform. The API has a base sensor interface and a set of sensor classes built on top. There are sensors like accelerometer, gyroscope, gravity sensor for motion, and ambient light sensors for the environment. Remote Management is managing a computer or a network from a remote location. It involves installing software and managing all activities on the systems/network, workstations, servers, or endpoints of a client, from a remote location. Remote administration refers to any method of controlling a computer from a remote location. Software that allows remote administration is becoming increasingly common and is often used when it is difficult or impractical to be physically near a system to use it.","title":"Question 6"},{"location":"Question_6/#6-part-1-sequential-logical-latches-and-flip-flops-counters-shift-registers-memories-part-2-new-elements-of-html5-new-features-of-css3-control-structures-in-web-scripts-sensor-through-a-web-page-providing-remote-management-systems-through-a-web-page","text":"","title":"6. PART 1 Sequential logical: Latches and Flip-Flops. Counters. Shift registers. Memories. PART 2 New elements of HTML5. New features of CSS3. Control structures in web scripts. Sensor through a web page. Providing remote management systems through a web page."},{"location":"Question_6/#part-1","text":"Sequential logic is a form of binary circuit design that has one or more inputs and one or more outputs, whose states are dependent in part on the previous states. Sequential logic circuits have some form of inherent memory built-in. Sequential logic circuits remember the conditions and stay fixed in their current state until the next clock signal changes one of the states. Latches are basic storage elements that operate with signal levels. Latches are level-sensitive devices and are useful for the design of asynchronous sequential circuits. There are two basic latches called the SR latch and the D latch. SR latch is a circuit with two cross-coupled NOR gates or two cross-coupled NAND gates with two inputs labeled S for set and R for a reset with two outputs Q and Q prime. This latch has two useful states. When the output Q is 1 and Q prime is 0, the latch is said to be inset state. When Q is 0 and Q prime is 1, then it is in a reset state. Normally the outputs Q and Q prime complement each other. An SR Nor latch has these states: When S is 0 and R is 1, then the output Q is 0 and Q prime is 1. This is the reset condition. Now if R goes back to 0, the reset state remains, now S and R are 0 but the previous output has been stored as memory. When S is 1 and R is 0, then Q prime is 0 and Q is 1. This is the set state. Now if S goes back to 0, the circuit remains in the set state. When S and R are both 1, then Q and Q prime become 0, this violates that both outputs must complement each other, this condition is avoided by making sure that 1s are not applied to both inputs simultaneously, this is the invalid state. To fix the drawback of the invalid state where both inputs are 1, we use the D latch, which has a single input D by sending the same signal to both S and R but placing an inverter in front of either one of them. This ensures that the input to one is always the opposite of the input to the other. Flip-Flops are just edge-triggered latches, it only changes state when a control signal goes from high to low or low to high. This makes using flip-flops with clock signals possible. We have SR flip-flops and D flip-flops which are the same as the latches. We have other flip-flops like JK flip-flop and T flip-flop. Counters are devices that store the number of times a particular event or process has occurred, often in relationship to a clock. A 4-bit ripple counter will count from 0000 or 0 to 1111 or 15. This can be made by chaining 4 T flip-flops together. Each clock pulse causes a change that ripples through the chain of flip flops with a delay. We also have synchronous counters which use the same clock signal on all flip-flops, this uses more circuitry but has no delay. There are also ring counters which are composed of flip-flops connected into a shift register, with the output of the last flip-flop fed to the input of the first, making a circular or ring structure. There are two types of ring counters, a straight ring counter connects the output of the last shift register to the first shift register input, this circulates a single one or zero bit around the ring. A twisted ring counter connects the complement of the output of the last shift register to the input of the first register and circulates a stream of ones followed by zeros around the ring. Flip-flops can be used to store a single bit of binary data. To store multiple bits of data, we need multiple flip-flops, N flip-flops connected to store n bits of data are called registers. A shift register is a type of digital circuit using a cascade of flip-flops where the output of one flip-flop is connected to the input of the next. They share a single clock signal which causes the data stores in the system to shift from one location to the next. By connecting the last flip-flop back to the first, the data can cycle within the shifters for extended periods and in this form, they are used as a form of computer memory. The registers which shift the bits to the left are called shift left registers and the registers which will shift the bits to the right are called shift right registers. We have 4 basic types of shift registers: Serial in serial out \u2013 these allow serial input and produce serial output. Serial in parallel out \u2013 these allow serial input and produce a parallel output. Parallel in serial out \u2013 these allow parallel input and produce a serial output. Parallel in parallel out \u2013 these allow parallel input and produce a parallel output. System memory is like a human brain. It is used to store data and instructions. Computer memory is the storage space in computers where data to be processed and instructions required for processing are stored. The memory is divided into a large number of small parts. Each part is called a cell and each location or cell has a unique address that varies from zero to memory size minus one. Memory is primarily of two types, internal memory like cache memory and primary memory, and external memory like magnetic disk, optical disk, or flash storage.","title":"Part 1"},{"location":"Question_6/#part-2","text":"HTML 5 introduced the following new elements: Article \u2013 represents an independent piece of content of a document, such as a block entry or newspaper article. Aside \u2013 Represents a piece of content that is only slightly related to the rest of the page. Audio \u2013 defines an audio file. Canvas \u2013 This is used for rendering dynamic bitmap graphics on the fly, such as graphs or games. Command \u2013 Represents a command the user can invoke. Datalist \u2013 Together with the new list attribute for input, can be used to make combo boxes. Details \u2013 Represents additional information or controls which the user can obtain on demand. Embed \u2013 Defines external interactive content or plugin. Figure \u2013 Represents a piece of self-contained flow content, typically referenced as a single unit from the main flow of the document. Footer \u2013 Represents a footer for a section and can contain information about the author, copyright information, etc. Header \u2013 Represents a group of introductory or navigational aids. Group \u2013 represents the header of a section. Keygen \u2013 Represents a control for key pair generation. Mark \u2013 Represents a run of text in one document marked or highlighted for reference purposes. Meter \u2013 Represents a measurement such as a disk usage. Nav \u2013 Represents a section of the document intended for navigation. Output \u2013 Represents some type of output, such as from a calculation done through scripting. Progress \u2013 Represents a completion of a task, such as downloading or when performing a series of expensive operations. Ruby \u2013 Together with rt and RP allows for marking up ruby annotations. Section \u2013 Represents a generic document or application section. Time \u2013 Represents a date or time. Video \u2013 Defines a video file. Wbr \u2013 Represents a line break opportunity. New features of CSS3 are as follows: Advanced animations \u2013 We can utilize both transition and animation when it is required to change a component starting with one state moving onto the next. With transitions, a user can make float or mouse down effects or trigger the animation by changing the style of a component with JavaScript. Multiple backgrounds and gradient \u2013 With multiple backgrounds, creators can stack various pictures as backgrounds of a component. Each picture or layer can be moved and animated with ease. CSS3 also allows for gradients as backgrounds. Multiple column layouts \u2013 This feature enables web designers to display their content in multiple sections with alternatives like column-width, column-gap, etc. Opacity \u2013 This property can make components more transparent. The opacity ranges from 0 which is transparent to 1 which is opaque. Rounded corner \u2013 This feature is very famous among social media giants. Rounded corners can make a site look tidier. Selectors \u2013 these are patterns or elements and other terms that tell the browser which HTML elements should be selected to have the CSS property values inside the rule applied to them. The elements selected by the selector are called the subject of the selector. Control structures are programming constructs that determine which statements or procedures are executed at a given point in a program, either based on the evaluation of one or more variables or in response to some external input. In the absence of control structures, program statements will execute sequentially or in the order in which they appear in the code. There are two basic kinds of control structures \u2013 conditional and iterative. A conditional control structure typically defines a sequence of one or more program statements that will be executed if a particular condition is met. An iterative control structure loops through or iterates a sequence of program statements repeatedly until some predetermined exit condition is met. Program loops can be for example a counting loop that iterates a fixed number of times and then exits the loop. The number of iterations is determined by the value of a counter variable. In web scripts we have some basic types of control structures: If-else \u2013 This evaluates a condition as a true or false value, if the value is true, the block following if statement is executed, if this is false then the block following else is executed. We can only execute one of the two blocks for a given expression. Switch \u2013 The switch statement allows us to make multiple if-else constructs more elegantly. We have a statement that might have multiple outputs, for each discrete output we have a different switch case. We also have a default case for when none of the given cases are met. For a given expression only one case can be executed at a time. For loop \u2013 This control structure has a counter variable and will run a block of code for a specified number of times, specified by the counter variable. Once this number has been reached, the program exits the loop. For in \u2013 This control structure iterates through the enumerable properties of a JavaScript object. While loop \u2013 This loop executes a block of code over and over until a certain condition is met. This condition is defined outside the loop and can be changed within the loop. Once this condition is met, the loop exits. Try catch \u2013 The try-catch block is used to handle exceptions. The code is first sent to the try block, if it doesn\u2019t throw an error, the next catch block is ignored, and program flow continues. If the try block throws an error, the control is transferred to the catch block which will execute the given exception handler. Sensor data is used by many web apps to enable immersive gaming, fitness tracking, and augmented reality applications. The Generic Sensor API is a set of interfaces that expose sensor devices to the web platform. The API has a base sensor interface and a set of sensor classes built on top. There are sensors like accelerometer, gyroscope, gravity sensor for motion, and ambient light sensors for the environment. Remote Management is managing a computer or a network from a remote location. It involves installing software and managing all activities on the systems/network, workstations, servers, or endpoints of a client, from a remote location. Remote administration refers to any method of controlling a computer from a remote location. Software that allows remote administration is becoming increasingly common and is often used when it is difficult or impractical to be physically near a system to use it.","title":"Part 2"},{"location":"Question_7/","text":"7. PART 1 Provide the necessary steps and technologies for developing a sample software product on a choosen platform. Describe the benefits and difficulties of the platform, the implementation steps, and the most widely used current technologies. PART 2 Implementation of control structures in assembly (control program flow, branching, looping) Part 1 Software is planned, created, tested, and deployed, this cycle is called a Software Development Life Cycle or SDLC. Various SDLC methodologies were popular in a certain time frame and were slowly replaced by the next one. Waterfall Model: The waterfall model is broken down into sequential phases. In this model, each phase must be completed before the next phase can begin and there is no overlapping in the phases. The outcome of one phase acts as the input for the next phase sequentially. This model has 6 phases: Requirement gathering and analysis System Design Implementation Integration and Testing Deployment of system Maintenance Advantages: This model is simple and easy to understand and easy to manage due to its rigidity. All phases are processed one at a time which means it has very well-defined stages with deliverables that can be easily assessed. Disadvantages: There is no working software until the end of the life cycle. This introduces lots of risk and uncertainty. This model can get overwhelming for complex projects or long-term projects. This type of model is also not suited for projects which have a risk of changing their requirements. It is difficult to measure progress within the stages. Iterative Model: In this model, we start with a simple implementation of a small set of software requirements and iteratively enhance versions until the complete system is implemented and ready to be deployed. We do not require a full specification of requirements to start. On each iteration, the project is reviewed, and modifications are made on the next iteration. Each iteration flows through the design and development, testing, and implementation phases. Advantages: A working software can be developed early in the life cycle. Results are obtained early, and progress is easy to measure. This type of model is cheaper to change the requirements for. The testing phase is simpler as it is only concerned with the changes in the current iteration. It is easier to analyze risk since risks can be identified on each iteration. Disadvantages: This type of model requires more resources, even though the cost to change the requirements is less, more resources are required to execute the many iterations. This is not suitable for smaller projects. The end of the project is not clearly defined which is a risk. Spiral Model: This model is a combination of iterative models and takes aspects of the sequential flow like in the waterfall model. This model has four phases, a software project is repeatedly passed through these phases in iterations called spirals. These phases are: Identification \u2013 This involves gathering the business requirements in the initial spiral. In subsequent spirals, the subsystem requirements are identified in each iteration. Design \u2013 This phase starts with conceptual design in the initial spiral. In subsequent spirals, it involves architecture design, logic design, product, and final design. Constructor builds \u2013 This is where the actual software development happens. In the initial spiral, the software is simply a proof of concept or POC. In subsequent spirals, it is developed further. Evaluation and risk analysis \u2013 This phase includes identifying, estimating, and monitoring risks such as schedule slippage or cost overrun. The customer provides feedback on every iteration of this phase. Advantages: It\u2019s easy to change the requirements. This model allows for quick iterations of software early in the life cycle. Development can be divided into smaller parts and riskier parts can be developed in later spirals. Disadvantages: Management for such a model is more complex and the end of the project is not clearly defined. This is not suitable for small-scale projects. Since there are many intermediate stages, it requires extensive documentation. Agile Model: This model breaks the product into small incremental builds. These builds are provided in iteration where each iteration typically lasts from one to three weeks. Every iteration includes cross functioning teams working on areas like: Planning Requirement analysis Design Coding Unit testing Acceptance testing At the end of the iteration, a working product is displayed to the customer. In Agile, tasks are divided into time boxes to deliver specific features for a release. Each build is incremental in terms of features and the final build contains all features required by the customer. This is the most popular model used in SDLC today. Agile has 4 main principles: Individuals and interactions \u2013 Self-organization and motivation are important as well as co-location and pair programming. Working software \u2013 There must be a demo working software that best communicates to the customer to give updates and understand new requirements instead of simply documentation. Customer collaboration \u2013 Continuous customer interaction is very important since all the requirements are not established at the very start, these evolve with the input of the customer. Responding to change \u2013 Agile development is focused on quick responses to change and continuous development. Advantages: It is a very realistic approach and promotes teamwork and cross-training. Functionality can be developed rapidly and demonstrated. This works for both fixed and changing requirements. There is a working software early in the life cycle. This model is easy to manage and gives flexibility to developers. Disadvantages: This model requires a plan, an agile leader, and an agile project manager. Depends heavily on customer interaction, which means if the customer is not clear then the project can become slow or hard to materialize. Transfer of technology to new team members might be difficult due to a lack of extensive documentation. There are some famous agile frameworks like SCRUM where a product owner will dictate some requirements which are put in the product backlog which is managed by a scrum master. Some sprints can last from one or two weeks with daily scrum meetings to give small updates and talk about roadblocks. At the end of a sprint, a version is delivered which is showcased to the customer. We also have Kanban which is a scheduling system like Jira which includes 4 main columns which are to-do, in progress, testing, and done. Tickets are created and tasks are moved from left to right as they are done. This is completely transparent to the team and the customer. Part 2 Control structures are a way to specify the flow of control in programs. They analyze and choose the direction in which a program flows based on certain parameters or conditions. The three basic control structures are Sequence, which is the default control structure where instructions are executed one after the other. The next basic type is conditional control structures, which allow the program to follow many options of paths depending on a given condition. The last type of control structure is iterative where instructions are executed in the body of a loop. Assembly language low-level control structures make extensive use of labels. These control structures usually transfer control between two points in the program. We specify the destination of such a transfer using a statement label, a label consists of a valid identifier and a colon. The three basic types of control structures are present in the assembly and are: Sequential \u2013 In assembly, these are basic arithmetic, logical, and bit operations where data is moved and copied. An example would be \u2018MOV EAX, EBX\u2019 where we move the 4 bytes in memory at address ebx into eax. Conditional or branching \u2013 In assembly these structures consist of direct and indirect jumps. Here we choose between two or more alternative paths, in assembly, this is done by using two types of instructions: a compare instruction like CMP which compares the two values, this is simply a subtract instruction internally. This is followed by a jump statement which will go to the instruction label which satisfies the given condition. There are two types of jumps, conditional jump instruction like jump if equal JE will go to the label if the two values are equal, which means the output of the compare instruction must be zero. The other type of jump instruction is an unconditional jump. This is performed by the JMP instruction. This type of jump instruction is used to jump on a particular location unconditionally, that is there is no need to satisfy any condition for the jump to take place. Some examples of conditional jump instructions are JNE or jump if not equal, JG or jump if greater, JGE, jump if equal or greater, JL or jump if lower, JLE or jump if lower. An unconditional jump example could be JMP followed by the label which is a direct jump or It can be followed by a register or a memory address. An example of conditional jump instruction can be that we have two registers AH and CH and we have moved a value into them. Next, we can compare these two with the CMP instruction followed by AH and then CH. We can then define some conditional jump instructions like JE followed by a label like L1, this instruction will be executed if the value in AH and CH are equal, we can also have an instruction like JL followed by a label like L2, we will jump to L2 if AH is less than CH. Both L1 and L2 will point to code blocks where we can execute whatever logic we need to. Iterative or looping \u2013 In assembly, these are looping structures like WHILE, DO WHILE, and FOR. They can be implemented using the JMP instruction. These loops must have an exit or break statement to avoid infinite loops. Infinite loops are usually a programmer\u2019s error, but event loops and task schedulers are examples of an infinite loop. Processors also have a newer LOOP instruction to execute loops more conveniently. An example of a loop that will execute a block for a fixed number of times with JMP instruction could be if we move the value 5 to the register AL. Then we will define a label for example L1, inside this code block we will decrease the value of AL by one using the DEC instruction on each loop iteration. Next, we can use a conditional jump statement like JNZ followed by L1, this code will run 5 times, when AL reached 0, we will not go back into the loop but exit it. We can also use the LOOP instruction to create a loop. An example could be if we move the value 5 in the ECX register and define a loop L1. This loop can simply have the instruction LOOP followed by L1 or the label we want to iterate over. The LOOP instruction decrements the value of ECX and compares it with zero, if the value in ECX is equal to zero, the program jumps to the L1 label, otherwise, it exits the loop.","title":"Question 7"},{"location":"Question_7/#7-part-1-provide-the-necessary-steps-and-technologies-for-developing-a-sample-software-product-on-a-choosen-platform-describe-the-benefits-and-difficulties-of-the-platform-the-implementation-steps-and-the-most-widely-used-current-technologies-part-2-implementation-of-control-structures-in-assembly-control-program-flow-branching-looping","text":"","title":"7. PART 1 Provide the necessary steps and technologies for developing a sample software product on a choosen platform. Describe the benefits and difficulties of the platform, the implementation steps, and the most widely used current technologies. PART 2 Implementation of control structures in assembly (control program flow, branching, looping)"},{"location":"Question_7/#part-1","text":"Software is planned, created, tested, and deployed, this cycle is called a Software Development Life Cycle or SDLC. Various SDLC methodologies were popular in a certain time frame and were slowly replaced by the next one. Waterfall Model: The waterfall model is broken down into sequential phases. In this model, each phase must be completed before the next phase can begin and there is no overlapping in the phases. The outcome of one phase acts as the input for the next phase sequentially. This model has 6 phases: Requirement gathering and analysis System Design Implementation Integration and Testing Deployment of system Maintenance Advantages: This model is simple and easy to understand and easy to manage due to its rigidity. All phases are processed one at a time which means it has very well-defined stages with deliverables that can be easily assessed. Disadvantages: There is no working software until the end of the life cycle. This introduces lots of risk and uncertainty. This model can get overwhelming for complex projects or long-term projects. This type of model is also not suited for projects which have a risk of changing their requirements. It is difficult to measure progress within the stages. Iterative Model: In this model, we start with a simple implementation of a small set of software requirements and iteratively enhance versions until the complete system is implemented and ready to be deployed. We do not require a full specification of requirements to start. On each iteration, the project is reviewed, and modifications are made on the next iteration. Each iteration flows through the design and development, testing, and implementation phases. Advantages: A working software can be developed early in the life cycle. Results are obtained early, and progress is easy to measure. This type of model is cheaper to change the requirements for. The testing phase is simpler as it is only concerned with the changes in the current iteration. It is easier to analyze risk since risks can be identified on each iteration. Disadvantages: This type of model requires more resources, even though the cost to change the requirements is less, more resources are required to execute the many iterations. This is not suitable for smaller projects. The end of the project is not clearly defined which is a risk. Spiral Model: This model is a combination of iterative models and takes aspects of the sequential flow like in the waterfall model. This model has four phases, a software project is repeatedly passed through these phases in iterations called spirals. These phases are: Identification \u2013 This involves gathering the business requirements in the initial spiral. In subsequent spirals, the subsystem requirements are identified in each iteration. Design \u2013 This phase starts with conceptual design in the initial spiral. In subsequent spirals, it involves architecture design, logic design, product, and final design. Constructor builds \u2013 This is where the actual software development happens. In the initial spiral, the software is simply a proof of concept or POC. In subsequent spirals, it is developed further. Evaluation and risk analysis \u2013 This phase includes identifying, estimating, and monitoring risks such as schedule slippage or cost overrun. The customer provides feedback on every iteration of this phase. Advantages: It\u2019s easy to change the requirements. This model allows for quick iterations of software early in the life cycle. Development can be divided into smaller parts and riskier parts can be developed in later spirals. Disadvantages: Management for such a model is more complex and the end of the project is not clearly defined. This is not suitable for small-scale projects. Since there are many intermediate stages, it requires extensive documentation. Agile Model: This model breaks the product into small incremental builds. These builds are provided in iteration where each iteration typically lasts from one to three weeks. Every iteration includes cross functioning teams working on areas like: Planning Requirement analysis Design Coding Unit testing Acceptance testing At the end of the iteration, a working product is displayed to the customer. In Agile, tasks are divided into time boxes to deliver specific features for a release. Each build is incremental in terms of features and the final build contains all features required by the customer. This is the most popular model used in SDLC today. Agile has 4 main principles: Individuals and interactions \u2013 Self-organization and motivation are important as well as co-location and pair programming. Working software \u2013 There must be a demo working software that best communicates to the customer to give updates and understand new requirements instead of simply documentation. Customer collaboration \u2013 Continuous customer interaction is very important since all the requirements are not established at the very start, these evolve with the input of the customer. Responding to change \u2013 Agile development is focused on quick responses to change and continuous development. Advantages: It is a very realistic approach and promotes teamwork and cross-training. Functionality can be developed rapidly and demonstrated. This works for both fixed and changing requirements. There is a working software early in the life cycle. This model is easy to manage and gives flexibility to developers. Disadvantages: This model requires a plan, an agile leader, and an agile project manager. Depends heavily on customer interaction, which means if the customer is not clear then the project can become slow or hard to materialize. Transfer of technology to new team members might be difficult due to a lack of extensive documentation. There are some famous agile frameworks like SCRUM where a product owner will dictate some requirements which are put in the product backlog which is managed by a scrum master. Some sprints can last from one or two weeks with daily scrum meetings to give small updates and talk about roadblocks. At the end of a sprint, a version is delivered which is showcased to the customer. We also have Kanban which is a scheduling system like Jira which includes 4 main columns which are to-do, in progress, testing, and done. Tickets are created and tasks are moved from left to right as they are done. This is completely transparent to the team and the customer.","title":"Part 1"},{"location":"Question_7/#part-2","text":"Control structures are a way to specify the flow of control in programs. They analyze and choose the direction in which a program flows based on certain parameters or conditions. The three basic control structures are Sequence, which is the default control structure where instructions are executed one after the other. The next basic type is conditional control structures, which allow the program to follow many options of paths depending on a given condition. The last type of control structure is iterative where instructions are executed in the body of a loop. Assembly language low-level control structures make extensive use of labels. These control structures usually transfer control between two points in the program. We specify the destination of such a transfer using a statement label, a label consists of a valid identifier and a colon. The three basic types of control structures are present in the assembly and are: Sequential \u2013 In assembly, these are basic arithmetic, logical, and bit operations where data is moved and copied. An example would be \u2018MOV EAX, EBX\u2019 where we move the 4 bytes in memory at address ebx into eax. Conditional or branching \u2013 In assembly these structures consist of direct and indirect jumps. Here we choose between two or more alternative paths, in assembly, this is done by using two types of instructions: a compare instruction like CMP which compares the two values, this is simply a subtract instruction internally. This is followed by a jump statement which will go to the instruction label which satisfies the given condition. There are two types of jumps, conditional jump instruction like jump if equal JE will go to the label if the two values are equal, which means the output of the compare instruction must be zero. The other type of jump instruction is an unconditional jump. This is performed by the JMP instruction. This type of jump instruction is used to jump on a particular location unconditionally, that is there is no need to satisfy any condition for the jump to take place. Some examples of conditional jump instructions are JNE or jump if not equal, JG or jump if greater, JGE, jump if equal or greater, JL or jump if lower, JLE or jump if lower. An unconditional jump example could be JMP followed by the label which is a direct jump or It can be followed by a register or a memory address. An example of conditional jump instruction can be that we have two registers AH and CH and we have moved a value into them. Next, we can compare these two with the CMP instruction followed by AH and then CH. We can then define some conditional jump instructions like JE followed by a label like L1, this instruction will be executed if the value in AH and CH are equal, we can also have an instruction like JL followed by a label like L2, we will jump to L2 if AH is less than CH. Both L1 and L2 will point to code blocks where we can execute whatever logic we need to. Iterative or looping \u2013 In assembly, these are looping structures like WHILE, DO WHILE, and FOR. They can be implemented using the JMP instruction. These loops must have an exit or break statement to avoid infinite loops. Infinite loops are usually a programmer\u2019s error, but event loops and task schedulers are examples of an infinite loop. Processors also have a newer LOOP instruction to execute loops more conveniently. An example of a loop that will execute a block for a fixed number of times with JMP instruction could be if we move the value 5 to the register AL. Then we will define a label for example L1, inside this code block we will decrease the value of AL by one using the DEC instruction on each loop iteration. Next, we can use a conditional jump statement like JNZ followed by L1, this code will run 5 times, when AL reached 0, we will not go back into the loop but exit it. We can also use the LOOP instruction to create a loop. An example could be if we move the value 5 in the ECX register and define a loop L1. This loop can simply have the instruction LOOP followed by L1 or the label we want to iterate over. The LOOP instruction decrements the value of ECX and compares it with zero, if the value in ECX is equal to zero, the program jumps to the L1 label, otherwise, it exits the loop.","title":"Part 2"},{"location":"Question_8/","text":"8. PART 1 Concept, typical applications and requirements of embedded systems. Real-time and reactive systems. Embedded systems architecture. Hardware and software layers. Embedded software: system software layer and application software layer. PART 2 Functions and services of the MRTG and Nagios network management systems. Part 1 An embedded system is any computer system contained within a product or embedded into another product that is not described as a computer. These are different from general-purpose computers, instead, they are custom made for a given purpose, they run software on dedicated hardware which might be terrible as a general-purpose computer but will excel in the task it was made for. Embedded systems have three main components, hardware, software, and firmware. The requirements of embedded systems change as per the application, for example, an embedded system in a fire alarm might only have a very low power single microprocessor and some sensors and actuators, it must operate in a wide range of temperature and humidity values and must consume as little energy as possible since it is highly likely that it will be working off a battery. Some other applications of embedded systems are digital watches, washing machines, cameras, automobiles, etc. Real-time systems are computer systems that monitor, respond to, or control an external environment. The environment is connected to the computer system through sensors, actuators, and other I/O interfaces. This computer system must meet various timing and other constraints that are imposed on it by the real-time behavior of the external world to which it is interfaced. These systems are also called reactive systems because their primary purpose is to respond to or react to signals from their environment. These types of systems are usually a component of a larger system thus they are embedded systems. Embedded systems come in two broad architecture types, Von Neumann architecture and Harvard architecture. The von Neumann architecture was proposed by Hungarian computer scientists John Von Neumann. In this architecture, one data bus exists for both instruction and data. Because of this, the CPU does one operation at a time, it can either fetch an instruction from memory or perform a read/write operation on the data. A fetch and data operation cannot occur simultaneously. The processor takes two clock cycles to execute, it will fetch a code in a separate cycle and read/write in a separate cycle. This architecture is simple and less time-consuming. The Harvard architecture on the other hand has separate storage and signal buses for instruction and data. Using separate internal buses, we can access the program instructions and data. This allows for fetch and reads/write operations to occur at the same time using different buses. The CPU can use a single clock cycle, this makes the design more complex and is more time-consuming. The hardware in an embedded system is based around a microprocessor or microcontroller. The embedded system hardware also contains other elements like memory, I/O devices, expandable interfaces like a display or camera, chips for wireless communication protocols. The embedded system software is written to perform a particular function. It is typically written in a high-level format and then compiled down to provide code that can be lodged within a non-volatile memory within the hardware. For educational embedded system devices like raspberry-pi, the language to write software is typically python. For a wide range of embedded devices, we use embedded C++ or C. For mission-critical applications of embedded systems like the anti-lock brake system, the code could be written directly in assembly language to get the fastest response from the system. The system software layer is the software that is designed to provide a platform for other software. System software includes operating systems like Windows or macOS, game engines like Unity and Unreal Engine, and software as a service application like Amazon Web Services and Microsoft Azure. For embedded systems like raspberry pi, the system software of choice is Raspberry Pi OS which is a Debian-based operating system or Unix-like system. This operating system was specially written for the ARM-based CISC processors which run these single board computers, that is why they are extremely optimized. This system software is very elaborate compared to a lot of other embedded systems, it offers a fully functioning graphical user interface, very close to macOS or windows in appearance. Users can install packages or pieces of fully functioning software using the APT or advanced package tool. On the other hand, we have the very simple embedded system Arduino, which uses the system software called Xinu and includes very basic features. Another tool called Protothreads can be used to execute linear code in C, and this can be used without any underlying operating system. Application software on the other hand is software that performs very specific tasks for the end-user. The user will directly interact with a piece of this software, unlike system software that will run process abstract from the end-user, of course, the user can alter these system software processes but, in most cases, it will result in misbehavior of the system or even complete shutdown. Embedded application software is very specialized to the application the embedded system will be embedded in. The important thing about embedded application software compared to application software found on a general-purpose computer is that non or not all functions of embedded software are initiated or controlled via a human interface, but through machine interfaces instead. An example of embedded software can be for controlling lights in homes, this can run on a simple 8bit microcontroller with just a few kilobytes of memory on very little energy, compared to 64-bit modern processors using several gigabytes of memory to function in the case of general-purpose computers. Part 2 MRTG or multi-router traffic Grapher is a free software for monitoring and measuring the traffic load on network links. It allows the user to see traffic load on a network over time in a graphical form. It was originally built to monitor router traffic, but it has evolved as a tool to create graphs and statistics for almost anything. This software is written in Perl and runs on all major operating systems. MRTG uses the simple network management protocol or SNMP to send requests with two object identifiers OIDs to a device. The device, which must be SNMP-enabled, will have a management information base to look up the OID specified. After collecting the information, it will send back the saw data encapsulated in an SNMP protocol. MRTG records this data in a log on the client along with previously recorded data for the device. The software then creates an HTML document from the logs, containing a list of graphs detailing traffic for the selected devices in the server. MRTG can also be configured to run a script of command and parse its output for counter values. The MRTG website contains a large library of external scripts to enable monitoring of SQL database statistics, firewall rules, CPU fan RPMs, or other integer value data. MRTG measures two values, input, and output per target. It gets its data via an SNMP agent or through the output of a command line. The frequency of data collection is typically every five minutes, but it can be configured to different time intervals as well. It creates an HTML page per target that features four graphs as GIF or PNG images. Results are plotted vs time into the day, week, month, and year graphs, with the input as a full green area and the output as a blue line. MRTG will automatically scale the Y-axis of the graphs to show the most detail and it will calculate the max, average and current values for both input and output on the HTML page. We can also make it send warning emails if the values are above a certain threshold. The RRDtool or round-robin database tool is an implementation of MRTG which aims to handle time-series data like network bandwidth but also includes other data like temperature and CPU load. A lot of other widely used tools have been made which are based on RRDtool like Munin and Cacti. Nagios is a free and open-source computer software application that monitors systems, networks, and infrastructure. Nagios offers to monitor and alerting services for servers, switches, and applications. It alerts users when things go wrong and alert them a second time when the problem has been resolved. It is continuous monitoring software which is a process to detect, report, and respond to all attacks which occur in the infrastructure. Continuous monitoring starts when the deployment is done on the production servers. There are several benefits to continuous monitoring like detecting all server and network problems, finding the root cause of the failure, helping reduce the maintenance cost, helping in troubleshooting the performance issues, helping updating infrastructure before it gets outdated, and monitoring the complete infrastructure every second. Nagios is a great choice since it can monitor database servers like SQL Server, Oracle, MySQL, Postgres, and others, it gives application-level information and also allows for protocol monitoring like HTTP, FTP SNMP, and SSH protocol monitoring, provides active development, it has an excellent community of open-source developers working hard to make it as bug-free as possible, it runs on virtually all operating systems, and it can ping to see if the host is reachable. Nagios helps in getting rid of periodic testing, it detects split-second failures and reduces maintenance cost without sacrificing performance. It also provides timely notification to the management of control and breakdown. Nagios has a server-agent architecture. The Nagios server is installed on the host and plugins are installed on the remote servers which are to be monitored. Nagios sends a signal through a process scheduler to run the plugins on the local or remote servers. These plugins collect the data like CPU usage and memory usage and send it back to the scheduler, then the process schedules send the notification to the admins and update the Nagios graphical user interface.","title":"Question 8"},{"location":"Question_8/#8-part-1-concept-typical-applications-and-requirements-of-embedded-systems-real-time-and-reactive-systems-embedded-systems-architecture-hardware-and-software-layers-embedded-software-system-software-layer-and-application-software-layer-part-2-functions-and-services-of-the-mrtg-and-nagios-network-management-systems","text":"","title":"8. PART 1 Concept, typical applications and requirements of embedded systems. Real-time and reactive systems. Embedded systems architecture. Hardware and software layers. Embedded software: system software layer and application software layer. PART 2 Functions and services of the MRTG and Nagios network management systems."},{"location":"Question_8/#part-1","text":"An embedded system is any computer system contained within a product or embedded into another product that is not described as a computer. These are different from general-purpose computers, instead, they are custom made for a given purpose, they run software on dedicated hardware which might be terrible as a general-purpose computer but will excel in the task it was made for. Embedded systems have three main components, hardware, software, and firmware. The requirements of embedded systems change as per the application, for example, an embedded system in a fire alarm might only have a very low power single microprocessor and some sensors and actuators, it must operate in a wide range of temperature and humidity values and must consume as little energy as possible since it is highly likely that it will be working off a battery. Some other applications of embedded systems are digital watches, washing machines, cameras, automobiles, etc. Real-time systems are computer systems that monitor, respond to, or control an external environment. The environment is connected to the computer system through sensors, actuators, and other I/O interfaces. This computer system must meet various timing and other constraints that are imposed on it by the real-time behavior of the external world to which it is interfaced. These systems are also called reactive systems because their primary purpose is to respond to or react to signals from their environment. These types of systems are usually a component of a larger system thus they are embedded systems. Embedded systems come in two broad architecture types, Von Neumann architecture and Harvard architecture. The von Neumann architecture was proposed by Hungarian computer scientists John Von Neumann. In this architecture, one data bus exists for both instruction and data. Because of this, the CPU does one operation at a time, it can either fetch an instruction from memory or perform a read/write operation on the data. A fetch and data operation cannot occur simultaneously. The processor takes two clock cycles to execute, it will fetch a code in a separate cycle and read/write in a separate cycle. This architecture is simple and less time-consuming. The Harvard architecture on the other hand has separate storage and signal buses for instruction and data. Using separate internal buses, we can access the program instructions and data. This allows for fetch and reads/write operations to occur at the same time using different buses. The CPU can use a single clock cycle, this makes the design more complex and is more time-consuming. The hardware in an embedded system is based around a microprocessor or microcontroller. The embedded system hardware also contains other elements like memory, I/O devices, expandable interfaces like a display or camera, chips for wireless communication protocols. The embedded system software is written to perform a particular function. It is typically written in a high-level format and then compiled down to provide code that can be lodged within a non-volatile memory within the hardware. For educational embedded system devices like raspberry-pi, the language to write software is typically python. For a wide range of embedded devices, we use embedded C++ or C. For mission-critical applications of embedded systems like the anti-lock brake system, the code could be written directly in assembly language to get the fastest response from the system. The system software layer is the software that is designed to provide a platform for other software. System software includes operating systems like Windows or macOS, game engines like Unity and Unreal Engine, and software as a service application like Amazon Web Services and Microsoft Azure. For embedded systems like raspberry pi, the system software of choice is Raspberry Pi OS which is a Debian-based operating system or Unix-like system. This operating system was specially written for the ARM-based CISC processors which run these single board computers, that is why they are extremely optimized. This system software is very elaborate compared to a lot of other embedded systems, it offers a fully functioning graphical user interface, very close to macOS or windows in appearance. Users can install packages or pieces of fully functioning software using the APT or advanced package tool. On the other hand, we have the very simple embedded system Arduino, which uses the system software called Xinu and includes very basic features. Another tool called Protothreads can be used to execute linear code in C, and this can be used without any underlying operating system. Application software on the other hand is software that performs very specific tasks for the end-user. The user will directly interact with a piece of this software, unlike system software that will run process abstract from the end-user, of course, the user can alter these system software processes but, in most cases, it will result in misbehavior of the system or even complete shutdown. Embedded application software is very specialized to the application the embedded system will be embedded in. The important thing about embedded application software compared to application software found on a general-purpose computer is that non or not all functions of embedded software are initiated or controlled via a human interface, but through machine interfaces instead. An example of embedded software can be for controlling lights in homes, this can run on a simple 8bit microcontroller with just a few kilobytes of memory on very little energy, compared to 64-bit modern processors using several gigabytes of memory to function in the case of general-purpose computers.","title":"Part 1"},{"location":"Question_8/#part-2","text":"MRTG or multi-router traffic Grapher is a free software for monitoring and measuring the traffic load on network links. It allows the user to see traffic load on a network over time in a graphical form. It was originally built to monitor router traffic, but it has evolved as a tool to create graphs and statistics for almost anything. This software is written in Perl and runs on all major operating systems. MRTG uses the simple network management protocol or SNMP to send requests with two object identifiers OIDs to a device. The device, which must be SNMP-enabled, will have a management information base to look up the OID specified. After collecting the information, it will send back the saw data encapsulated in an SNMP protocol. MRTG records this data in a log on the client along with previously recorded data for the device. The software then creates an HTML document from the logs, containing a list of graphs detailing traffic for the selected devices in the server. MRTG can also be configured to run a script of command and parse its output for counter values. The MRTG website contains a large library of external scripts to enable monitoring of SQL database statistics, firewall rules, CPU fan RPMs, or other integer value data. MRTG measures two values, input, and output per target. It gets its data via an SNMP agent or through the output of a command line. The frequency of data collection is typically every five minutes, but it can be configured to different time intervals as well. It creates an HTML page per target that features four graphs as GIF or PNG images. Results are plotted vs time into the day, week, month, and year graphs, with the input as a full green area and the output as a blue line. MRTG will automatically scale the Y-axis of the graphs to show the most detail and it will calculate the max, average and current values for both input and output on the HTML page. We can also make it send warning emails if the values are above a certain threshold. The RRDtool or round-robin database tool is an implementation of MRTG which aims to handle time-series data like network bandwidth but also includes other data like temperature and CPU load. A lot of other widely used tools have been made which are based on RRDtool like Munin and Cacti. Nagios is a free and open-source computer software application that monitors systems, networks, and infrastructure. Nagios offers to monitor and alerting services for servers, switches, and applications. It alerts users when things go wrong and alert them a second time when the problem has been resolved. It is continuous monitoring software which is a process to detect, report, and respond to all attacks which occur in the infrastructure. Continuous monitoring starts when the deployment is done on the production servers. There are several benefits to continuous monitoring like detecting all server and network problems, finding the root cause of the failure, helping reduce the maintenance cost, helping in troubleshooting the performance issues, helping updating infrastructure before it gets outdated, and monitoring the complete infrastructure every second. Nagios is a great choice since it can monitor database servers like SQL Server, Oracle, MySQL, Postgres, and others, it gives application-level information and also allows for protocol monitoring like HTTP, FTP SNMP, and SSH protocol monitoring, provides active development, it has an excellent community of open-source developers working hard to make it as bug-free as possible, it runs on virtually all operating systems, and it can ping to see if the host is reachable. Nagios helps in getting rid of periodic testing, it detects split-second failures and reduces maintenance cost without sacrificing performance. It also provides timely notification to the management of control and breakdown. Nagios has a server-agent architecture. The Nagios server is installed on the host and plugins are installed on the remote servers which are to be monitored. Nagios sends a signal through a process scheduler to run the plugins on the local or remote servers. These plugins collect the data like CPU usage and memory usage and send it back to the scheduler, then the process schedules send the notification to the admins and update the Nagios graphical user interface.","title":"Part 2"},{"location":"Question_9/","text":"9. PART 1 Programmable logic devices. Designing a digital system in hardware description language, and implementing it in FPGA devices. PART 2 Basic concepts of system engineering, different paradigms. Characteristics of the classical methods: waterfall, evolution, incremental, agile methods. Fundamentals and patterns of OOdesign. MVC Part 1 Programmable logic devices or PLD is electronic component used to build reconfigurable digital circuits. Unlike integrated circuits which consist of logic gates and have a fixed function, a PLD has an undefined function at the time of manufacture. Before the PLD can be used in a circuit it must be programmed or reconfigured by using a specialized program. PLDs have programmable logic, compared to fixed logic which has permanent configurations. Fixed logic is great for a final production design, but it cannot be used to experiment or add new features, we could keep creating new fixed logic chips for every new feature to be tested but that is not cost-efficient. PLDs are easy to program, and affordable, new code can be developed on them and tested in live electronic circuits. Every Boolean logic can be decomposed into product-of-sum POS or sum-of-product SOP, PLDs are typically built with an array of AND gates and an array of OR gates to implement the SOP. A simple programming technology is to use fuses, in the original state all fuses are intact, once programmed the fuses are blown along the paths that must be removed to obtain the correct logic. PLDs are broadly classified into simple programmable logic devices and high-capacity programmable logic devices. Some examples of SPLDs are ROM or read-only memory, PLA or programmable logic array, and PAL or programmable array logic. A widely used example of HCPLD is the FPGA or field-programmable gate array. Hardware description language or HDL is a specialized computer language used to describe the structure and behavior of electronic circuits and digital logic circuits. A hardware description language enables a precise, formal description of an electronic circuit that allows for automated analysis and simulation of an electronic circuit. Most hardware description languages look like other software programming languages like C or ALGOL, a textual description consisting of expressions, statements, and control structures. One important difference between most programming languages and HDLs is that HDLs explicitly include the notion of time. HDLs provide flexible modeling capabilities and can express large complex designs with tens of millions of logic gates. Today there are two main HDLs used, VHDL and Verilog. VHDL is the more popular choice of the two, it stands for Very High-Speed Integration Circuit HDL and it is standardized by IEEE. VHDL allows the user to define data types, supports parallel or concurrent procedure calls, it contains a built-in mod operator, but it is more difficult to learn compared to Verilog. Verilog is easier to learn and is used for describing digital systems like a network switch or FPGAs. Verilog supports design at many layers of abstraction: behavioral level, register transfer level, and gate-level. Behavioral level describes a system concurrent algorithm. Every algorithm is sequential, functions and blocks are the main elements. Register-transfer level designs specify the characteristics of a circuit using operations and the transfer of data between the registers. In gate-level design, the characteristics of a system are described by logical links and their timing properties. All signals are discrete signals and can only have definite logical values, logical 1, logical 0, unknown logic value X, and high impedance state Z. The usable operations are predefined logic primitives or basic logic gates. Gate level design is not widely used since it is the lowest level and is inefficient, instead, this code is generated using synthesis tools. We also define the physical wire that represents the physical wire used for connections of gates or modules using the Wire keyword. FPGA stands for field-programmable gate array. FPGAs are essentially a huge array of gates that can be programmed and reconfigured with code. Some modern FPGAs also have more complex blocks like memory controllers, high-speed communications interfaces, PCIe endpoints, etc. but at the core, we have grids of gates that can be programmed. The most widely used FPGAs are manufactured by Xilinx, which is a subsidiary of fixed logic general-purpose processor manufacturer AMD. A basic Xilinx FPGA board can be programmed in the Vivado integrated development environment using the middle layer of abstraction called the register transfer level or RTL which lies between the strictly behavioral and the pure gate-level model. In RTL we can describe a sequence of data flow from a set of registers to the next at each clock cycle. RTL code can be converted to Verilog. Using Verilog, we can define modules where we state the wire and the clock. We begin initializing the clock to 0 and begin defining an endpoint for the clock. We begin the clock and then call whatever code block we want to, for example, we can define another module that will assign a variable to a wire and its complement to another wire. Using Vivido IDE, we can use the simulation model and run to see the output in the simulation in a waveform format. We can also inspect the waveform to make sure our Verilog module is working as expected. Connecting our physical FPGA board to the development computer, we can then run this script on the board and see the output by assigning the values to some LEDs for visual representation, in our case we can program the original value and its complement can be two different LEDs, for our defined clock period, these two LEDs can blink alternatively since they have a NOT gate between them. Part 2 A system is a collection of different elements that interact to produce results that are not obtainable by the elements alone. An automobile is made up of thousands of parts and each part must work with the others if the vehicle is to function as desired. From a functional viewpoint, systems have inputs, processes, and outputs. Inputs are the resources put into a system, processes combine the resources to produce the output which can be a product, service, or enterprise. From a physical viewpoint, the system consists of mechanical, electrical, and software components. These systems are built in a way to provide feedback on if the system is working correctly or not. Systems engineering is when different engineers in different fields come together to work on a larger system, it is an interdisciplinary field. Systems engineering have five core concepts: Value \u2013 Systems provide value when they meet the needs of stakeholders. Context \u2013 The context of the system is important; the engineers need to consider where the products will be used. Trade-offs \u2013 Trade-offs can cost, time and performance and must be evaluated during designing. Abstraction \u2013 Engineers need the ability to abstract a design conception independent of the solution. Interdisciplinarity \u2013 Interdisciplinarity supports the systems approach which means the teams must comprise members for various disciplines to meet every requirement of the stakeholders. In software engineering which is a part of systems engineering where the system is the software product, we have different paradigms: Waterfall \u2013 This is a linear sequential model. In this model, each phase must be completed before the next phase can begin and there is no overlapping in the phases. These phases are requirement analysis, system design, implementation, testing, deployment, and maintenance. This method is not used anymore due to better methods like Agile. Evolution \u2013 This is a software engineering model where the software is developed initially, then it is updated timely for various reasons like to add new features or to remove obsolete functionality. The evolution process includes fundamental activities of change analysis, release planning, system implementation, and releasing a system to customers. Incremental \u2013 This model of software engineering is when the requirements are divided into multiple standalone modules of the software development cycle. Each module goes through the requirements, design, implementation, and testing phases. Every subsequent release of the module adds function to the previous release, this process continues until the complete system is achieved. Agile \u2013 This model focuses on adaptability and customer satisfaction by rapid delivery of working software products. The agile method breaks the product into small incremental builds. These builds are provided in iteration, where each iteration typically lasts from one to three weeks. Every iteration involves cross functioning teams working on areas like planning, requirement analysis, design, coding, unit testing, etc. Customer interaction is the backbone of agile, the product development has complete transparency to the customer with timely working demos instead of lots of documentation. The customer then provides feedback and can change requirements or add to them. This is the most widely used model today and has many useful frameworks like SCRUM and Kanban. Object-oriented programs are made up of objects. An object packages both data and procedures. Procedures are typically called methods. Objects have procedures that can access and modify the data fields themselves. Most popular object-oriented programming languages are class-based like Java and C sharp. Object-oriented programming is based on 4 pillars, which are Abstraction, Polymorphism, Inheritance, and Encapsulation. Abstraction is when we separate the interface of a class from its implementation and focus on the interface, this is like treating the system as a black box and not worrying about how it is working. We only present a clean and easy-to-use interface via the class\u2019s member functions. Polymorphism is when objects of different types can be accessed through the same interface, each type can provide its independent implementation of this interface. Inheritance allows us to create subclasses from parent classes, the subclass will inherit all objects and methods from its parent class and can be overridden to change the functionality as well. Encapsulation in OOP is when we bind the data and functions into a single class, by doing so we hide private details of a class from the outside world and only expose functionality that is important for interfacing with it. Design patterns in OO refer to using patterns that can be followed to easily solve problems in object-oriented programming: Creational \u2013 Creational patterns have to do with the creation of objects. It emphasizes the automatic creation of objects; a function or method can call the code necessary to instantiate a new object on the programmer\u2019s behalf. This allows us to create new objects faster where there might be many defaults, in the case where we might need to change a default, we can do so explicitly for that object. Structural \u2013 Structural design patterns have to do with making larger structures from smaller objects and classes. This allows us to leverage relationships between classes and objects to form larger structures, thus we use inheritance here. Behavioral \u2013 Behavioral patterns are concerned with the communication of different objects with each other, or the interaction between objects and how they affect each other. An example could be a bottle of water object and a human object, the human drinks the bottle of water using the bottle of water\u2019s drink method. This causes the thirst attribute of the human object to become false and also causes the water level attribute of the bottle of water to be lower in value. MVC architecture or Model View Controller architecture pattern turns complex applications development into a much more manageable process. It allows several developers to simultaneously work on the application. MVC has three components, Model is the backend that contains all the data logic, View is the frontend or graphical user interface, Controller is the brains of the applications that control how data is displayed. MVC pattern is widely used for modern web applications since it allows the application to be scalable, maintainable, and easy to expand. MVC pattern helps us break up the frontend and backend code into separate components. This way it is much easier to manage and make changes to either side without them interfering with each other. The model component is where the data is managed, data can come from a database, API, or a JSON object. The view is the user interface, view\u2019s job is to decide what the user will see on the screen and how. The Controller is the brain component, it is responsible to pull, modify and provide data to the user. Essentially the controller is the link between the view and model. Some frameworks using MVC concepts are Django and Ruby on Rails.","title":"Question 9"},{"location":"Question_9/#9-part-1-programmable-logic-devices-designing-a-digital-system-in-hardware-description-language-and-implementing-it-in-fpga-devices-part-2-basic-concepts-of-system-engineering-different-paradigms-characteristics-of-the-classical-methods-waterfall-evolution-incremental-agile-methods-fundamentals-and-patterns-of-oodesign-mvc","text":"","title":"9. PART 1 Programmable logic devices. Designing a digital system in hardware description language, and implementing it in FPGA devices. PART 2 Basic concepts of system engineering, different paradigms. Characteristics of the classical methods: waterfall, evolution, incremental, agile methods. Fundamentals and patterns of OOdesign. MVC"},{"location":"Question_9/#part-1","text":"Programmable logic devices or PLD is electronic component used to build reconfigurable digital circuits. Unlike integrated circuits which consist of logic gates and have a fixed function, a PLD has an undefined function at the time of manufacture. Before the PLD can be used in a circuit it must be programmed or reconfigured by using a specialized program. PLDs have programmable logic, compared to fixed logic which has permanent configurations. Fixed logic is great for a final production design, but it cannot be used to experiment or add new features, we could keep creating new fixed logic chips for every new feature to be tested but that is not cost-efficient. PLDs are easy to program, and affordable, new code can be developed on them and tested in live electronic circuits. Every Boolean logic can be decomposed into product-of-sum POS or sum-of-product SOP, PLDs are typically built with an array of AND gates and an array of OR gates to implement the SOP. A simple programming technology is to use fuses, in the original state all fuses are intact, once programmed the fuses are blown along the paths that must be removed to obtain the correct logic. PLDs are broadly classified into simple programmable logic devices and high-capacity programmable logic devices. Some examples of SPLDs are ROM or read-only memory, PLA or programmable logic array, and PAL or programmable array logic. A widely used example of HCPLD is the FPGA or field-programmable gate array. Hardware description language or HDL is a specialized computer language used to describe the structure and behavior of electronic circuits and digital logic circuits. A hardware description language enables a precise, formal description of an electronic circuit that allows for automated analysis and simulation of an electronic circuit. Most hardware description languages look like other software programming languages like C or ALGOL, a textual description consisting of expressions, statements, and control structures. One important difference between most programming languages and HDLs is that HDLs explicitly include the notion of time. HDLs provide flexible modeling capabilities and can express large complex designs with tens of millions of logic gates. Today there are two main HDLs used, VHDL and Verilog. VHDL is the more popular choice of the two, it stands for Very High-Speed Integration Circuit HDL and it is standardized by IEEE. VHDL allows the user to define data types, supports parallel or concurrent procedure calls, it contains a built-in mod operator, but it is more difficult to learn compared to Verilog. Verilog is easier to learn and is used for describing digital systems like a network switch or FPGAs. Verilog supports design at many layers of abstraction: behavioral level, register transfer level, and gate-level. Behavioral level describes a system concurrent algorithm. Every algorithm is sequential, functions and blocks are the main elements. Register-transfer level designs specify the characteristics of a circuit using operations and the transfer of data between the registers. In gate-level design, the characteristics of a system are described by logical links and their timing properties. All signals are discrete signals and can only have definite logical values, logical 1, logical 0, unknown logic value X, and high impedance state Z. The usable operations are predefined logic primitives or basic logic gates. Gate level design is not widely used since it is the lowest level and is inefficient, instead, this code is generated using synthesis tools. We also define the physical wire that represents the physical wire used for connections of gates or modules using the Wire keyword. FPGA stands for field-programmable gate array. FPGAs are essentially a huge array of gates that can be programmed and reconfigured with code. Some modern FPGAs also have more complex blocks like memory controllers, high-speed communications interfaces, PCIe endpoints, etc. but at the core, we have grids of gates that can be programmed. The most widely used FPGAs are manufactured by Xilinx, which is a subsidiary of fixed logic general-purpose processor manufacturer AMD. A basic Xilinx FPGA board can be programmed in the Vivado integrated development environment using the middle layer of abstraction called the register transfer level or RTL which lies between the strictly behavioral and the pure gate-level model. In RTL we can describe a sequence of data flow from a set of registers to the next at each clock cycle. RTL code can be converted to Verilog. Using Verilog, we can define modules where we state the wire and the clock. We begin initializing the clock to 0 and begin defining an endpoint for the clock. We begin the clock and then call whatever code block we want to, for example, we can define another module that will assign a variable to a wire and its complement to another wire. Using Vivido IDE, we can use the simulation model and run to see the output in the simulation in a waveform format. We can also inspect the waveform to make sure our Verilog module is working as expected. Connecting our physical FPGA board to the development computer, we can then run this script on the board and see the output by assigning the values to some LEDs for visual representation, in our case we can program the original value and its complement can be two different LEDs, for our defined clock period, these two LEDs can blink alternatively since they have a NOT gate between them.","title":"Part 1"},{"location":"Question_9/#part-2","text":"A system is a collection of different elements that interact to produce results that are not obtainable by the elements alone. An automobile is made up of thousands of parts and each part must work with the others if the vehicle is to function as desired. From a functional viewpoint, systems have inputs, processes, and outputs. Inputs are the resources put into a system, processes combine the resources to produce the output which can be a product, service, or enterprise. From a physical viewpoint, the system consists of mechanical, electrical, and software components. These systems are built in a way to provide feedback on if the system is working correctly or not. Systems engineering is when different engineers in different fields come together to work on a larger system, it is an interdisciplinary field. Systems engineering have five core concepts: Value \u2013 Systems provide value when they meet the needs of stakeholders. Context \u2013 The context of the system is important; the engineers need to consider where the products will be used. Trade-offs \u2013 Trade-offs can cost, time and performance and must be evaluated during designing. Abstraction \u2013 Engineers need the ability to abstract a design conception independent of the solution. Interdisciplinarity \u2013 Interdisciplinarity supports the systems approach which means the teams must comprise members for various disciplines to meet every requirement of the stakeholders. In software engineering which is a part of systems engineering where the system is the software product, we have different paradigms: Waterfall \u2013 This is a linear sequential model. In this model, each phase must be completed before the next phase can begin and there is no overlapping in the phases. These phases are requirement analysis, system design, implementation, testing, deployment, and maintenance. This method is not used anymore due to better methods like Agile. Evolution \u2013 This is a software engineering model where the software is developed initially, then it is updated timely for various reasons like to add new features or to remove obsolete functionality. The evolution process includes fundamental activities of change analysis, release planning, system implementation, and releasing a system to customers. Incremental \u2013 This model of software engineering is when the requirements are divided into multiple standalone modules of the software development cycle. Each module goes through the requirements, design, implementation, and testing phases. Every subsequent release of the module adds function to the previous release, this process continues until the complete system is achieved. Agile \u2013 This model focuses on adaptability and customer satisfaction by rapid delivery of working software products. The agile method breaks the product into small incremental builds. These builds are provided in iteration, where each iteration typically lasts from one to three weeks. Every iteration involves cross functioning teams working on areas like planning, requirement analysis, design, coding, unit testing, etc. Customer interaction is the backbone of agile, the product development has complete transparency to the customer with timely working demos instead of lots of documentation. The customer then provides feedback and can change requirements or add to them. This is the most widely used model today and has many useful frameworks like SCRUM and Kanban. Object-oriented programs are made up of objects. An object packages both data and procedures. Procedures are typically called methods. Objects have procedures that can access and modify the data fields themselves. Most popular object-oriented programming languages are class-based like Java and C sharp. Object-oriented programming is based on 4 pillars, which are Abstraction, Polymorphism, Inheritance, and Encapsulation. Abstraction is when we separate the interface of a class from its implementation and focus on the interface, this is like treating the system as a black box and not worrying about how it is working. We only present a clean and easy-to-use interface via the class\u2019s member functions. Polymorphism is when objects of different types can be accessed through the same interface, each type can provide its independent implementation of this interface. Inheritance allows us to create subclasses from parent classes, the subclass will inherit all objects and methods from its parent class and can be overridden to change the functionality as well. Encapsulation in OOP is when we bind the data and functions into a single class, by doing so we hide private details of a class from the outside world and only expose functionality that is important for interfacing with it. Design patterns in OO refer to using patterns that can be followed to easily solve problems in object-oriented programming: Creational \u2013 Creational patterns have to do with the creation of objects. It emphasizes the automatic creation of objects; a function or method can call the code necessary to instantiate a new object on the programmer\u2019s behalf. This allows us to create new objects faster where there might be many defaults, in the case where we might need to change a default, we can do so explicitly for that object. Structural \u2013 Structural design patterns have to do with making larger structures from smaller objects and classes. This allows us to leverage relationships between classes and objects to form larger structures, thus we use inheritance here. Behavioral \u2013 Behavioral patterns are concerned with the communication of different objects with each other, or the interaction between objects and how they affect each other. An example could be a bottle of water object and a human object, the human drinks the bottle of water using the bottle of water\u2019s drink method. This causes the thirst attribute of the human object to become false and also causes the water level attribute of the bottle of water to be lower in value. MVC architecture or Model View Controller architecture pattern turns complex applications development into a much more manageable process. It allows several developers to simultaneously work on the application. MVC has three components, Model is the backend that contains all the data logic, View is the frontend or graphical user interface, Controller is the brains of the applications that control how data is displayed. MVC pattern is widely used for modern web applications since it allows the application to be scalable, maintainable, and easy to expand. MVC pattern helps us break up the frontend and backend code into separate components. This way it is much easier to manage and make changes to either side without them interfering with each other. The model component is where the data is managed, data can come from a database, API, or a JSON object. The view is the user interface, view\u2019s job is to decide what the user will see on the screen and how. The Controller is the brain component, it is responsible to pull, modify and provide data to the user. Essentially the controller is the link between the view and model. Some frameworks using MVC concepts are Django and Ruby on Rails.","title":"Part 2"}]}